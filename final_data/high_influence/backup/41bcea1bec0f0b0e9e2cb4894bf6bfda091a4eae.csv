citationID,citationName,citedReferences
7701c8f57f187f087c33d2053620a1893f54479e,A Hybrid Vision-Based Method of Encountered Wave Field Measurement for Navigating Surface Vehicles,a61de626cd5c949baa47f06ac1a864cfaca67ad5
53886b2e1cecf88748cf410387604f50e560a673,PMIndoor: Pose Rectified Network and Multiple Loss Functions for Self-Supervised Monocular Indoor Depth Estimation,5f985b914756155c92ebf474409be176bc1a84b4
299b63f28f9853a589d316e5514d4d923200f8e0,ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
266c6dacaeee8c86b6a364bd34635f8384c2c200,Depth Estimation from a Single Optical Encoded Image using a Learned Colored-Coded Aperture,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
94ef2e2d9033cd09e7513d5aa01d7971386eb5a7,A Dual Encoder–Decoder Network for Self-Supervised Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
2d87ad25d0ad74c40bd9ad90e5e61b1764f592cf,SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
4f66cdc5d329ca7aca1fa59fdd67ccebea607597,Uncertainty Guided Self-Supervised Monocular Depth Estimation Based on Monte Carlo Method,cddd92203c8deb022a29b512b11050da531c5f3b
cb88b7d30a71605fdf4fce9fdbf135c8023691a7,Digging into Depth Priors for Outdoor Neural Radiance Fields,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
44314b3277b55ea65495d6c502e28a63748061dc,InfraNet: Accurate forehead temperature measurement framework for people in the wild with monocular thermal infrared camera,cddd92203c8deb022a29b512b11050da531c5f3b
ab1ec9a5455eef09ff6c7f38676120f2157c29c2,MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
ebf8f76341f07b947d86550bd6f3313183ad6a68,SimCol3D - 3D Reconstruction during Colonoscopy Challenge,cddd92203c8deb022a29b512b11050da531c5f3b
46ff2f74a6e9fcab0bb75cf13a5943d050ef5ac6,Probabilistic multi-modal depth estimation based on camera–LiDAR sensor fusion,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
842182174ebd9e070101c85aa16c0818e5363c42,The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
82321364c74ba03154b300af5aadfaa68eaec12e,Trap Attention: Monocular Depth Estimation with Manual Traps,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
c0e6a2858578281ff44d1e14b5b45fae61e687c4,ARephotography: Revisiting Historical Photographs using Augmented Reality,d77d5c4c55a223512460793669f3016a4efb37db
8c727a7d2c93c99991c246277c622c454ac528ee,Depth Estimation Based on Monocular Camera Sensors in Autonomous Vehicles: A Self-supervised Learning Approach,cddd92203c8deb022a29b512b11050da531c5f3b
b36668a69eae938addf43e7c5681993e78d17d5f,GINA-3D: Learning to Generate Implicit Neural Assets in the Wild,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
4d0e0cceb00f7a52346e8fc385b3d17213175d02,Single Image Depth Prediction Made Better: A Multivariate Gaussian Take,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
e90a3a087736afadeaa5c8ff6d02723623bb9da8,URNet: An UNet-Based Model with Residual Mechanism for Monocular Depth Estimation,acf0b6745708457a53d5327eea345c0bcf466e97$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
8ec5909aaedcfff93f85a0b8032cd6da5c24e12a,Unified Perception: Efficient Depth-Aware Video Panoptic Segmentation with Minimal Annotation Costs,ae89592317675c9c7642a3976c3a064cef736f92
f9516f2b0e1816e87fd70aeedcbfb12cff341eb2,Monocular Depth Estimation using Diffusion Models,cddd92203c8deb022a29b512b11050da531c5f3b
2198e134f1f61fdc685816ddaf8656876ab00c2e,Monocular metasurface camera for passive single-shot 4D imaging,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
6505eeb75083e233d88e3616a1ae624cbcb63dd6,Self-Supervised Monocular Depth Estimation with Self-Reference Distillation and Disparity Offset Refinement,cddd92203c8deb022a29b512b11050da531c5f3b
4983b3555f3abf02c2bb00808f2b0d48881eaf32,VA-DepthNet: A Variational Approach to Single Image Depth Prediction,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
ebaa8b0896fe714524b4af1cf44ac837531a6735,High level structure recognition in single urban images using a CNN and SuperPixels,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
79d755f43a691926014249a1f7d80541173cff2c,Depth estimation of supervised monocular images based on semantic segmentation,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
9f7971b6d710c52c60683ed65bb9a4bd0380aa8d,FG-Depth: Flow-Guided Unsupervised Monocular Depth Estimation,421e6c7247f41c419a46212477d7b29540cbf7b1
85917316be4805ab909d4f73bd6cd3dcd778a400,In Search of Basement Indicators from Street View Imagery Data: An Investigation of Data Sources and Analysis Strategies,cddd92203c8deb022a29b512b11050da531c5f3b
b8e0f0cb386b54c512f9e87092664e5e6dae3cd5,Joint learning of frequency and spatial domains for dense image prediction,3635881d5632816df7762f2c588138c0baa339ef
959c50155d0b32ef4d472cb6e5aefa9f83b03fe6,GOOD: Exploring Geometric Cues for Detecting Objects in an Open World,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
d6c477aea7c4aa89f9cab1025ac20926fea31601,City-scale distance estimation via near-infrared trispectral light extinction in bad weather,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
605ae33386e3c19bc8b3c0d846cffe6a8c380e47,SfM-TTR: Using Structure from Motion for Test-Time Refinement of Single-View Depth Networks,ae89592317675c9c7642a3976c3a064cef736f92
417ae18a1a2d60c07f15c408b804a70f3a6717e3,Hybrid Transformer Based Feature Fusion for Self-Supervised Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
a8fb91618ceb52ab5d8985dde7e4185e69b6d51f,Application of Convolutional Neural Networks for Three-Dimensional Reconstruction of the Geometry of Objects in the Image,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
a635b54f9bfe6e777fe2348a64e28ae2a048ffc6,3D Scene Inference from Transient Histograms,cddd92203c8deb022a29b512b11050da531c5f3b
dd913cda160b22ce230aa79c2e37b188025ead1f,Depth completion of a single RGB-D image for integral imaging,cddd92203c8deb022a29b512b11050da531c5f3b
ea740e22ee958ad6fc4b7d0b7e408c39a4992b7d,Variational Depth Estimation on Hypersphere for Panorama,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
8b25da23901c93426a2ac8c3f1324a962a17f52f,Three-dimensional Monocular Image Reconstruction of Indoor Scene Based on Neural Network,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
9e97cfc0c7791aad9d1ff95b3ea51dc3176e1c35,Semantic Segmentation under Adverse Conditions: A Weather and Nighttime-aware Synthetic Data-based Approach,cddd92203c8deb022a29b512b11050da531c5f3b
2e2431e35a418cddc81447b2e6f4fdfc0cf123a3,Monocular Accumulated Depth Estimation with Recursive Feature Fusion,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db
02f0afe1f456811c4b59ca90e211a6c320e9cc8a,DELTAR: Depth Estimation from a Light-weight ToF Sensor and RGB Image,cddd92203c8deb022a29b512b11050da531c5f3b
37782456b662daca8b66e7ed27cf58db4fa9cb87,Semi-Supervised Depth Estimation by Multi-Task Learning,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
28227bc2f709616b606e10f72748a03cfc47cdbd,HoW-3D: Holistic 3D Wireframe Perception from a Single Image,88da9026bbedf408aec54b158b456627818cacf9
3e8eb241d5c8e4ee9f599919db4b730e71691e63,Globally Consistent Video Depth and Pose Estimation with Efficient Test-Time Training,a61de626cd5c949baa47f06ac1a864cfaca67ad5
444f5c010576d753dd99f7d270b314ede8be758e,A New Dynamic Routing Network for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
c45347944bf4ed90db315f71a8f95fb274d6868b,Monocular Depth Estimation Using Deep Learning: A Review,fdcde62b781ab7bd60aa76d4ec7328fbf9ab7c71$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
ca091fe0a6869a5168c6713bd7c81872d1e13394,PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation,ae89592317675c9c7642a3976c3a064cef736f92
db730f4be0d5d05c7f5dbcfd2978c1bf498c4b8d,Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on Dataset Mixtures with Uncalibrated Stereo Data,ae89592317675c9c7642a3976c3a064cef736f92
c6c518ccd441bae6fdc788a58b6d39db1f33f1a4,MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
37fc280c372b264d975441fd9fcd5435b0a4c943,PhoneDepth: A Dataset for Monocular Depth Estimation on Mobile Devices,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
fb57a98b39488c1f6c1e2a5575c5e82cc7e28a6d,Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e
7d1763539498a2e2ea70514664b8f320193f7b45,P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
00622d2594af8e033a2bafbd53354e03b2c30ad5,Improving Monocular Visual Odometry Using Learned Depth,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
5169163e649c53313ded2b2a187f9105768d3a22,Distortion-Aware Self-Supervised 360° Depth Estimation from A Single Equirectangular Projection Image,cddd92203c8deb022a29b512b11050da531c5f3b
58b81adbc1f1a15985f5e07051b5d9bf6fac8bff,From 2D to 3D: Re-thinking Benchmarking of Monocular Depth Prediction,cddd92203c8deb022a29b512b11050da531c5f3b
1e88b2fc4f38891ac24207fc1500dfa18e1887fc,Depth-Independent Depth Completion via Least Square Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
daee1a8ee8fc6b73812ae854716a87d5db962716,Neural Window Fully-connected CRFs for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
fc3c90a16aafafe320cfce72e29025b35ab5f21b,Does depth estimation help object detection?,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
35d4976befefe8026e74cbe987743df3b7fd57b5,Pyramid frequency network with spatial attention residual refinement module for monocular depth estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
c7d56d6dfd48661fcbf7d0c093279badd6591bf1,Semisupervised learning-based depth estimation with semantic inference guidance,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
6e76598db3aaa2426522f86cba509698fdacce42,Joint Learning of Frequency and Spatial Domains for Dense Predictions,3635881d5632816df7762f2c588138c0baa339ef
92951ea82ea84f91d188e60695c452fad81440f7,GLPanoDepth: Global-to-Local Panoramic Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
6a6b8726527505bbc9adbab201743970076461b5,Visual Micro-Pattern Propagation,cddd92203c8deb022a29b512b11050da531c5f3b
9ce9293296b37430a9918ade47688e8b1fa51fae,A Novel Method for Space Circular Target Detection in Machine Vision,421e6c7247f41c419a46212477d7b29540cbf7b1
2e1c70e9fc4135fa829dcecb8aee984510f72896,A Survey on RGB-D Datasets,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f89ab69b94c3251dac419ecea6fc841e13f73e7b,THE Benchmark: Transferable Representation Learning for Monocular Height Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
700063e5c89660fa654fc086c870b3534f4fe8d2,Multi-planar geometry and latent image recovery from a single motion-blurred image,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
0e5774b25904d925d9031fce70dc5659c06d9dba,What's Behind the Couch? Directed Ray Distance Functions (DRDF) for 3D Scene Reconstruction,ae89592317675c9c7642a3976c3a064cef736f92
787d3d4539282483affb028e1a342e7e01176905,Object-Aware Monocular Depth Prediction With Instance Convolutions,cddd92203c8deb022a29b512b11050da531c5f3b
238a5bb4b70775a0733877e62d063adfae678f66,MonoScene: Monocular 3D Semantic Scene Completion,ae89592317675c9c7642a3976c3a064cef736f92$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
41e0ae16e3a7a0b19323a7503d8531cfba7bce16,NVS-MonoDepth: Improving Monocular Depth Prediction with Novel View Synthesis,cddd92203c8deb022a29b512b11050da531c5f3b
436660b0f9f7f63178a993a950b7fd8b27f04976,Detail-preserving depth estimation from a single image based on modified fully convolutional residual network and gradient network,cddd92203c8deb022a29b512b11050da531c5f3b
5eddd334176b88c971439c7d6b339c95d51be545,MobileXNet: An Efficient Convolutional Neural Network for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
dec0ac4510d65616c887e3699807ff345dc4cf9e,Towards Real-Time Monocular Depth Estimation for Robotics: A Survey,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
10cd28124d8d8cd4ac901053a7e351e335276cf1,Towards Panoptic 3D Parsing for Single Image in the Wild,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
a7fa7d6841b97a4d769430ab48d4b44a18f7b11d,Self-Supervised Deep Monocular Depth Estimation With Ambiguity Boosting,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
bcb6bffe2671f4325df4c9c38933a6deeea7d38c,Smaller Residual Network for Single Image Depth Estimation,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$3635881d5632816df7762f2c588138c0baa339ef
b3be07fbf8d90de3c83b67ebfe99f7351b24e815,Depth Estimation of Single Defocused Images Based on Multi-Feature Fusion,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
e554b0588ad57bc9c7878029928e31c830cc50c3,X-Distill: Improving Self-Supervised Monocular Depth via Cross-Task Distillation,cddd92203c8deb022a29b512b11050da531c5f3b
18fac874dde0928f68c8319b69db85363762d6af,Joint Soft–Hard Attention for Self-Supervised Monocular Depth Estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f3e5923d928c8fe7b6d8ef4888edcb51d4da18f0,Lifting the Veil of Frequency in Joint Segmentation and Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
226d85b23aed752dac5cb36668a56434191c6856,PLNet: Plane and Line Priors for Unsupervised Indoor Depth Estimation,5f985b914756155c92ebf474409be176bc1a84b4
184d746d614f1fbfaf9707590bca6a629ad42729,DCPNet: A Densely Connected Pyramid Network for Monocular Depth Estimation,ae89592317675c9c7642a3976c3a064cef736f92$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
32906d6514c3e27e8cc0bdfd9e3880b0ed28a0a0,Enforcing Temporal Consistency in Video Depth Estimation,49531103099c8d17ea34eb09433688e84de4f35f
0caaff138d784456770c676cbc9623ece5e12dd0,Weakly-Supervised Single-view Dense 3D Point Cloud Reconstruction via Differentiable Renderer,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
9aa42ceb7669b9f6bc87d7d4aefb0b2d3636a627,Weakly-Supervised Monocular Depth Estimationwith Resolution-Mismatched Data,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
499410d731d088c8edc310168266dcaf36a267ad,Augmenting Depth Estimation with Geospatial Context,1f4789a2effea966c8fd10491fe859cfc7607137
95b49b7a537ff085f6290c671a2cd3360deeb704,Multitarget Vehicle Tracking and Motion State Estimation Using a Novel Driving Environment Perception System of Intelligent Vehicles,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$787827850b614135f6b432603afc90b58a8cc665$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
7d9ff1c5b8c53bf1fe638e41289413dfc105af8a,A Non-local Low Rank and Total Variation Approach for Depth Image Estimation,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
a5ad2967e11636481ccb1bce0c19bc0e4557e39a,StructDepth: Leveraging the structural regularities for self-supervised indoor depth estimation,a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
d59aa8a4aef10c749f907fb788650e6ec9fc2e44,SFA-MDEN: Semantic-Feature-Aided Monocular Depth Estimation Network Using Dual Branches,3635881d5632816df7762f2c588138c0baa339ef
9db3a6099fc14de22a26bf16b9b705891e30fe34,Probabilistic and Geometric Depth: Detecting Objects in Perspective,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
0464f9263a9f57884127a03871eefacc4c76053b,Self-supervised monocular depth estimation based on image texture detail enhancement,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
584690dccdc62e814b5d64bc9c3b1f4096b59c5f,Towards real-time monocular depth estimation for mobile systems,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
d78d129a206517a6dc2f2b163a1a2c16e9fb1d93,Self-Supervised Depth Estimation Leveraging Global Perception and Geometric Smoothness,3635881d5632816df7762f2c588138c0baa339ef$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
faf5a9329175801a560a49f03014da2535823d18,Monocular Depth Estimation Using Information Exchange Network,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
a868b61f141bce392a15b8db1a79a658ad03661e,SliceNet: deep dense depth estimation from a single indoor panorama using a slice-based representation,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
21fde3a3fab044a9b3568c71480764ad93ed1ff1,Patch-Wise Attention Network for Monocular Depth Estimation,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
b6b5b80911015a2572cb0c0ca5899d9b31044658,2.5D Visual Relationship Detection,cddd92203c8deb022a29b512b11050da531c5f3b
836fdf47f0e281825a4b9562fda65004936dc9bf,Exploring Chromatic Aberration and Defocus Blur for Relative Depth Estimation From Monocular Hyperspectral Image,49531103099c8d17ea34eb09433688e84de4f35f$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
2b16b6f6110e6aedb570c792fb4dcb995436fa40,Domain Adaptive Monocular Depth Estimation With Semantic Information,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
511d2774ddba66fa0fb7e4d48d8d440c7c4c1e49,On the Synergies Between Machine Learning and Binocular Stereo for Depth Estimation From Images: A Survey,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
1ddfe1af9c9e794f8e2301d65844433b81226493,StyHighNet: Semi-Supervised Learning Height Estimation from a Single Aerial Image via Unified Style Transferring,cddd92203c8deb022a29b512b11050da531c5f3b
02c785adf3cf7656adbc29c100b91e53382f4dbd,Monocular Depth Estimation Through Virtual-World Supervision and Real-World SfM Self-Supervision,49531103099c8d17ea34eb09433688e84de4f35f
22745de52341e297db64baa9409cd8b9234f3d22,Virtual Normal: Enforcing Geometric Constraints for Accurate and Robust Depth Prediction,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
c2b89e97718eb23d035c8f9d9d001ff1ddb1d28a,Joint Depth and Defocus Estimation From a Single Image Using Physical Consistency,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
c02c4a72d7d2b13c51628a81d096dff4d0380c68,Learning Steering Kernels for Guided Depth Completion,cddd92203c8deb022a29b512b11050da531c5f3b
188860f5c18e8443fea74d5b3080362c7f266b3d,Integrating Sensor Models in Deep Learning Boosts Performance: Application to Monocular Depth Estimation in Warehouse Automation,787827850b614135f6b432603afc90b58a8cc665
7742689b2ec332ecc83edec22f6e64f23569a9af,Monocular depth estimation based on a single image: a literature review,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1
41032653151b75175d769e5226158f4dcea54037,Predicting Relative Depth between Objects from Semantic Features,3635881d5632816df7762f2c588138c0baa339ef$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
8f207af2d473b1aa27b33381b5c8142cda993a23,Delivering Meaningful Representation for Monocular Depth Estimation,49531103099c8d17ea34eb09433688e84de4f35f
b50adb64d103f6497de0da8c222da88807f643be,Ordinal Depth Classification Using Region-based Self-attention,cddd92203c8deb022a29b512b11050da531c5f3b
b28c2599e1d3a1b05d1a51f849d06de5e4c1b38c,Multi-view 3D shape style transformation,ae89592317675c9c7642a3976c3a064cef736f92
f64bba38c37b1bb19672f5e0131ce9ac2ae97956,Object Reconstruction Based on Attentive Recurrent Network from Single and Multiple Images,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
3b3219e59587c97b4703601531d9e7cd8eb710c3,Worldsheet: Wrapping the World in a 3D Sheet for View Synthesis from a Single Image,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d77d5c4c55a223512460793669f3016a4efb37db
27b6749039e79be9357356f3abe232dc645b6623,Probabilistic Graph Attention Network With Conditional Kernels for Pixel-Wise Prediction,5f985b914756155c92ebf474409be176bc1a84b4
0e2c09024ed9423324358eb3a209170723a435ef,Rethinking Shape From Shading for Spoofing Detection,3635881d5632816df7762f2c588138c0baa339ef$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
62a9c2527b94328b85cbbe6c8fe630efd830d1e6,Disparity Estimation Using Stereo Images With Different Focal Lengths,c4b3896b4fbfaeb53d4babf4c856fab14f0601e4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
1083a32b18dcd4b729b4113dcb16c6960cb37ac7,Supervised depth estimation for visual perception on low-end platforms,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
b7353108e73d5d12002531204eebf4dce9257db8,Learning to Predict the 3D Layout of a Scene,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
0e101ff1d7b21dab50e2b72b2edd38a58ecc9667,SeasonDepth: Cross-Season Monocular Depth Prediction Dataset and Benchmark under Multiple Environments,cddd92203c8deb022a29b512b11050da531c5f3b
5dcfa5452ab62f34beba0fcd103288f07b01ecaa,"Deep Learning based Monocular Depth Prediction: Datasets, Methods and Applications",cddd92203c8deb022a29b512b11050da531c5f3b
d5295eafefaeb2237010e219a878462766854492,Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints,cddd92203c8deb022a29b512b11050da531c5f3b
4dfd4e52a975f41ecba6eb20516900583ac4b5a2,A loss-balanced multi-task model for simultaneous detection and segmentation,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
ebe46ba382d67dc90a3e1398e4bf6582d351ec4c,DynOcc: Learning Single-View Depth from Dynamic Occlusion Cues,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
754cb424e0f9cdcbe4be2e683d503a7e82130f75,Distortion-Aware Monocular Depth Estimation for Omnidirectional Images,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
679927ae340dbf5415adf98ea39c88f2e4fdae64,Learning Monocular Dense Depth from Events,cddd92203c8deb022a29b512b11050da531c5f3b
617ce6b13bfa599628f1c361d91db1e35ea007c1,A New Distributional Ranking Loss With Uncertainty: Illustrated in Relative Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
703a76591ef378090df4fc5a2b1572e22aa9e236,Novel Hybrid Neural Network for Dense Depth Estimation using On-Board Monocular Images,3635881d5632816df7762f2c588138c0baa339ef
dfc4de43d01092698f47d2329aaf08731086d2c4,Depth-aware salient object segmentation,1f4789a2effea966c8fd10491fe859cfc7607137
1fec4b7af0545f9d08f9359f0dc49d5726545b01,DASGIL: Domain Adaptation for Semantic and Geometric-Aware Image-Based Localization,cddd92203c8deb022a29b512b11050da531c5f3b
9be2bc3722394b2df143d3a6725bee8ac9209e36,Latent 3D Volume for Joint Depth Estimation and Semantic Segmentation from a Single Image,cddd92203c8deb022a29b512b11050da531c5f3b
c465793c452273dcf00dcacbbb0f11cf7d8c1352,Depth Estimation from Monocular Images and Sparse Radar Data,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
be7b258c6e50f32254aaa57a919bac9d5baf1481,Understanding of Curved Corridor Scenes Based on Projection of Spatial Right-Angles,fdcde62b781ab7bd60aa76d4ec7328fbf9ab7c71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
54065d21ad9f7b8597f14a39debcee383114b092,Adversarial Patch Attacks on Monocular Depth Estimation Networks,cddd92203c8deb022a29b512b11050da531c5f3b
1292ef59c77f74de6804e16db2c37bc2a3a02941,Towards General Purpose and Geometry Preserving Single-View Depth Estimation,ae89592317675c9c7642a3976c3a064cef736f92
e13a762cf10bf251b80dbca1a97dd57cc59da5ee,GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
460499cd6aa0350754dc4f7e0e1438706e250386,Bidirectional Attention Network for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
1c5915e6ada12a7332999cc26ce5815eaa04c08c,Adaptive Context-Aware Multi-Modal Network for Depth Completion,cddd92203c8deb022a29b512b11050da531c5f3b
9afbd92599c0d66f781c8a923a6b88521af3718e,Target distance measurement method using monocular vision,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
5588860b68a787000240721dfa6a4433587f082f,Recovering Depth from Still Images for Underwater Dehazing Using Deep Learning,3635881d5632816df7762f2c588138c0baa339ef
c1b3d2dd4a6257d53c334f9cf73aa1c695affe3b,When Perspective Comes for Free: Improving Depth Prediction with Camera Pose Encoding,3635881d5632816df7762f2c588138c0baa339ef
2879cdca17e197406d1dd8698ddd860169616728,Monocular Depth Prediction With Residual DenseASPP Network,cddd92203c8deb022a29b512b11050da531c5f3b
c6582cc3e3f1fd73c262c73071354ddae0cfefa9,Fine-tuning Monocular Depth-Estimator Artificial Neural Networks Trained on Synthetic RGB-D Data Sets for Real Scenes,cddd92203c8deb022a29b512b11050da531c5f3b
089b419fae460e52c7d6a69d12f32252a5930366,Increased-Range Unsupervised Monocular Depth Estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
8542e98f4d139b37e5b5f714b0a5ea005cc693fc,SharinGAN: Combining Synthetic and Real Data for Unsupervised Geometry Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
632563e6660ebc8a7ca970a0baf66def3270531e,SDC-Depth: Semantic Divide-and-Conquer Network for Monocular Depth Estimation,ae89592317675c9c7642a3976c3a064cef736f92
e2b8a7ac87efdc7696b5e943059d33c5a659cd88,Unsupervised Multi-View Constrained Convolutional Network for Accurate Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
631caae176a966470b488c4368d7aed36b01c04f,On the Uncertainty of Self-Supervised Monocular Depth Estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
222d4bee25a1ecb9923dc6920ea8b19cb4cb55d1,Multi Image Depth from Defocus Network with Boundary Cue for Dual Aperture Camera,cddd92203c8deb022a29b512b11050da531c5f3b
ff8c0d5b04403ac4005c5832f67d58202a159f1b,Depth Estimation From Single Image Through Multi-Path-Multi-Rate Diverse Feature Extractor,3635881d5632816df7762f2c588138c0baa339ef
43550e50110d6a500ac827e30f54f391aae5f8c7,Consistent video depth estimation,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
6d398862c3be9d9c1a9f55f42bc36e1a67b4cdca,On the Synergies between Machine Learning and Stereo: a Survey,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
cf480be3e805a68dcd5020539529660b6bb69303,Deep Recognition of Vanishing-Point-Constrained Building Planes in Urban Street Views,ae89592317675c9c7642a3976c3a064cef736f92
f0a2db7c5a07755436705f2c4a6f60a6122e8874,A self-supervised method of single-image depth estimation by feeding forward information using max-pooling layers,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
9c50d19707244af585314eb2f1a705f706082005,Towards Better Generalization: Joint Depth-Pose Learning Without PoseNet,a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
0d4051aa0f14f95a3ffa5f0d37db37327246e166,Modeling Defocus-Disparity in Dual-Pixel Sensors,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
311a220bcb3c405e8157d2e0a1977921efd08f1d,Data-Driven Indoor Scene Modeling from a Single Color Image with Iterative Object Segmentation and Model Retrieval,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
d177361ddf2765d509882b414a697e94d57dc59e,Self-Supervised Monocular Trained Depth Estimation Using Self-Attention and Discrete Disparity Volume,cddd92203c8deb022a29b512b11050da531c5f3b
d715add4b3da9c1c1537585d26a78a66fb0431c6,DeFeat-Net: General Monocular Depth via Simultaneous Unsupervised Representation Learning,a61de626cd5c949baa47f06ac1a864cfaca67ad5
f5d0082322c3a52039236fdcbccfb08a5f4f9872,Pix2Shape: Towards Unsupervised Learning of 3D Scenes from Images Using a View-Based Representation,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
c1a465b557f22dd0e66810bf5b3729d19eca29ab,Monocular depth estimation based on deep learning: An overview,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
7a17aba1325a7d2b404ea481507a549147dd3c4a,Low-viewpoint forest depth dataset for sparse rover swarms,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
b88fbc48e864c0985833b2171ae10479bf580766,Unsupervised Depth Estimation From Monocular Images For Autonomous Vehicles,49531103099c8d17ea34eb09433688e84de4f35f$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$787827850b614135f6b432603afc90b58a8cc665
a7c9cbc731eeacb09dd5d2671992da290ec2ea3c,Smart Cameras,a61de626cd5c949baa47f06ac1a864cfaca67ad5
255699b2e2094851d5c56915a75d1a1cdcb78426,Weakly supervised learning for image classification and potentially moving obstacles analysis,a61de626cd5c949baa47f06ac1a864cfaca67ad5
aebdfe58365eeec917d3734420d4d76d10487d57,Capturing the Geometry of Object Categories from Video Supervision,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
13549c8167c2a18b479f1ff6a9db0df18378680c,GrabAR: Occlusion-aware Grabbing Virtual Objects in AR,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
51221c21f2aa1c9ebefa9131d4d825656f3b1c0a,Depth Estimation of Computer Video Images Based on Deep Learning,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
fbcc98e3000e07d5dd689b5ee991ac1b3457fa0a,Object Depth Measurement from Monocular Images Based on Feature Segments,3635881d5632816df7762f2c588138c0baa339ef
02d865e555baf559d3fca78d2ec2f6ac84a57680,Parsing Indoor Scenes from RGB-D Image Using Superpixel and Region Merging,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
75d80d8037abf99ef2a54d7dc08b9ff69ae85638,Dilated Fully Convolutional Neural Network for Depth Estimation from a Single Image,5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
e7f0f6f5c300fd19cbdb607863bd55f1e854bc4b,An Unsupervised Monocular Image Depth Prediction Algorithm Based on Multiple Loss Deep Learning,cddd92203c8deb022a29b512b11050da531c5f3b
74467761227e2cb92eff703a64931240c055c5eb,On the Benefit of Adversarial Training for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
700537e6d57293628b7e23ea02e1db35de73e0f7,Deep Classification Network for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
266008a2c1cd2329f2de8ae77cb48478cccebb8a,Joint Image and Depth Estimation With Mask-Based Lensless Cameras,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
916190b8d38356d04c7d09b29a3edcbbe91baa18,Self-Supervised Learning for Autonomous Vehicles Perception: A Conciliation Between Analytical and Learning Methods,a61de626cd5c949baa47f06ac1a864cfaca67ad5
7508e859398b2f55f68af5680cb041acd582a53a,Depth Estimation From a Single Image Using Guided Deep Network,acf0b6745708457a53d5327eea345c0bcf466e97
631fe595f77b07350e64537c001290a1b017a539,Deep Monocular Depth Estimation in Partially-Known Environments,cddd92203c8deb022a29b512b11050da531c5f3b
01b0f3493e1cd470226e62e6ffc952e6f42dab46,Efficient Passive Sensing Monocular Relative Depth Estimation,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
ad895fea21a0d9f5d3aaa63af1873ad2b33716a3,GLoSH: Global-Local Spherical Harmonics for Intrinsic Image Decomposition,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
bce087b969a1d6a7b6771c6cbf30a4f2cacaea64,Monocular Depth Estimation Using Synthetic Images With Shadow Removal*,cddd92203c8deb022a29b512b11050da531c5f3b
da2db09a7326def59035938c1738b2d100a980d0,LIDAR and Monocular Camera Fusion: On-road Depth Completion for Autonomous Driving,cddd92203c8deb022a29b512b11050da531c5f3b
31f003cd31991f25736ee6ab46dbbb7c550c9afb,Monocular relative depth reordering by propagating confidence of local and global cues,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e
31ec53ef1134c98df971a0d65862b3f3eb274dfd,Self-Supervised Learning of Depth and Ego-motion with Differentiable Bundle Adjustment,cddd92203c8deb022a29b512b11050da531c5f3b
f397688d2f4e46d06d9082bc96c41e7c0eebebf3,Real-time Depth Estimation Using Recurrent CNN with Sparse Depth Cues for SLAM System,acf0b6745708457a53d5327eea345c0bcf466e97
cb88ab409f341a5f694b2df354be1a4bde32d457,Self-Supervised Learning of Depth and Motion Under Photometric Inconsistency,cddd92203c8deb022a29b512b11050da531c5f3b
1b20a7a9ce9e840d293040f5371ffc5bc996867a,Task-Aware Monocular Depth Estimation for 3D Object Detection,cddd92203c8deb022a29b512b11050da531c5f3b
cd0f05ff32abf554d9dfb606efa535669e125adf,Unsupervised Domain Adaptation for Depth Prediction from Images,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
bdc1abe786f9c9d43f94bc2801fb69b93e95b953,3D Neighborhood Convolution: Learning Depth-Aware Features for RGB-D and RGB Semantic Segmentation,cddd92203c8deb022a29b512b11050da531c5f3b
adc0fe92abe204e950889d2d0de4d9ef1c2f8af7,High Relief from Brush Painting,ae89592317675c9c7642a3976c3a064cef736f92
79c69eb08622e9b444b72982a1f9d5058f0bd300,Deep Learning-Based Obstacle Detection and Depth Estimation,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
d1aa06f42cfc9a2bea37da71734ad6ccedba8512,Depth Estimation from a Single Image using Multi Stream and Scale Deep Learning,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$3635881d5632816df7762f2c588138c0baa339ef
2fc18b1bd117c4e138916c22a570136b62edabad,"UASOL, a large-scale high-resolution outdoor stereo dataset",4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
659f2f9cbed63cce315a48942f99487d64c764ea,Object-Driven Multi-Layer Scene Decomposition From a Single Image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
cbdb852e0610f4fab1160a29c8ca4381a7c8035c,Mono-SF: Multi-View Geometry Meets Single-View Depth for Monocular Scene Flow Estimation of Dynamic Traffic Scenes,cddd92203c8deb022a29b512b11050da531c5f3b
e7f85b5da599d9e1aa47e5a2c8dc52ca5f0642b1,Structured Coupled Generative Adversarial Networks for Unsupervised Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
cc7b43a0538be1d1d0b452f355d5afa1ba18d633,"To Complete or to Estimate, That is the Question: A Multi-Task Approach to Depth Completion and Monocular Depth Estimation",cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
47e5adcdb42e5be764218e0ba7c50202ce3cec93,UM-Adapt: Unsupervised Multi-Task Adaptation Using Adversarial Cross-Task Distillation,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
cb9464a046758fe93e7a351b4a5d6e81e0ea6518,Semi-Supervised Adversarial Monocular Depth Estimation,5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
182e092f7b6758ffae58de0a7959775b8531bf4c,Adversarial View-Consistent Learning for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
f8dcd47bfdf0fa953366f6b11d2d64e5b9557a33,An automatic cluster-based approach for depth estimation of single 2D images,5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e
3c2c3eb19a74decb03ff37e058c3148caecd612a,Improving robot visual skills by means of a bio-inspired model,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
4a0e8ee9eece980b54c9899977a3db0af6b8f845,From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
c6f7424a362e9d61a762d493475df3dc6e84fade,Moving Indoor: Unsupervised Video Depth Learning in Challenging Environments,a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
7bd83b055702bc178aa26def5b6df463f8eab7b9,Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
e4013a86384e8604f2e429a56d7bb260b0990fb7,Deeper Monocular Depth Prediction via Long and Short Skip Connection,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
0310851bf5b947e0189718f45a8971a7534897ee,Pixel-Accurate Depth Evaluation in Realistic Driving Scenarios,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
9d293a9a04f364990130bd1daa7d8b2ad4491d8e,Learning to Reconstruct and Understand Indoor Scenes From Sparse Views,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$e36632f52c995e28896fa0663c39ae345d097da6
2156df4fc9f402ff331aca68c2c3f212c9728d53,Traffic Scene Depth Analysis Based on Depthwise Separable Convolutional Neural Network,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
51510a4f77b52886fc16bf8e4d9312ec10316920,A Survey on Deep Learning Architectures for Image-based Depth Reconstruction,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
63b604555ac2a0fbd77877d073984ba61e0b3aae,Generating and Exploiting Probabilistic Monocular Depth Estimates,cddd92203c8deb022a29b512b11050da531c5f3b
1dd676483a3680d5b782aab0520c8a42370aea9d,3D-RelNet: Joint Object and Relational Network for 3D Prediction,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
80a2d0c9e4722a63f0865f7a60b2a165c02df48d,FlexSight - A Flexible and Accurate System for Object Detection and Localization for Industrial Robots,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
3a7ea7e87f92e517666ae2a87801b2464e8d50d8,Connecting the Dots: Learning Representations for Active Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42,Soft Labels for Ordinal Regression,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
1831fb8b884d3686a638be5d05034d831e81b2e1,Monocular Depth Estimation Using Relative Depth Maps,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
4a06fa3178f9ea83d666b0c49a055db9cefbb237,Single Image Depth Estimation Trained via Depth From Defocus Cues,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
9253bbb391b817457897428e2d6e39a337345f5e,Geometry and uncertainty in deep learning for computer vision,668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
776d6a9647ddef2831299b2e71d623e824c5f25f,Monocular image depth estimation using dilated convolution and spatial pyramid polling structure,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
f13a4fb657b91b98649cb15d51d601bfc42feb47,Design Flow of Single Camera Motion Estimation Using GPU Accelerators,a31e9d09d90261fc68acffe097df592cfdcb7706
be046579236b7f4bf2abe8245cda7f6b9446c4df,Offset Aperture: A Passive Single-Lens Camera for Depth Sensing,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
0558ec4faec2abbbce593e30d50025a1d9369e24,On-the-fly dense 3D surface reconstruction for geometry-aware augmented reality.,3635881d5632816df7762f2c588138c0baa339ef$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
cf12d08381d463c6b261e7cde8c569a693469166,Deep monocular depth estimation leveraging a large-scale outdoor stereo dataset,ae89592317675c9c7642a3976c3a064cef736f92$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
54e8d23c097427dac84d6217d8a71a46db1c3f56,Deep Optics for Monocular Depth Estimation and 3D Object Detection,cddd92203c8deb022a29b512b11050da531c5f3b
22d2bf25883510c93c5264bef04bc0d62c80e704,Bayesian DeNet: Monocular Depth Prediction and Frame-Wise Fusion With Synchronized Uncertainty,421e6c7247f41c419a46212477d7b29540cbf7b1
e572cf63564e6d3a09415c027a3c9a7697c664ff,Online Adaptation through Meta-Learning for Stereo Depth Estimation,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
c615af9c71c8db9826440058a0a9ee26dba3bd60,Learning Monocular Depth Estimation Infusing Traditional Stereo Knowledge,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
c0229f788387c3cf8cbdeae93c773fde60b1b307,Planar Geometry and Latest Scene Recovery from a Single Motion Blurred Image,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
b0cf15563de2dc77d29d879d64b9cb59c8b68bde,Planar Geometry and Image Recovery from Motion-Blur,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
8d6b0a0afaa515e8c6cd97f608414c2c6ce83ae9,Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
824e9a61dee5b2f441d74c216c5eaf2a3765987e,CAM-Convs: Camera-Aware Multi-Scale Convolutions for Single-View Depth,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
4a78024c08490aa7687223bb2eabb29ac8bf4d41,Binary-Patterns Based Floor Recognition Suitable for Urban Scenes,cddd92203c8deb022a29b512b11050da531c5f3b
c279e565e950c4335060865b6ed5247b9cb5b4f2,Bilateral Cyclic Constraint and Adaptive Regularization for Unsupervised Monocular Depth Prediction,cddd92203c8deb022a29b512b11050da531c5f3b
dde47480f7efd36903d3e554256f6f1d185d6415,World From Blur,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
27ef68733362e8422d04cabcb40c357840ad5e98,Aggregation of Rich Depth-Aware Features in a Modified Stacked Generalization Model for Single Image Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
85e7810acb23acc71db6defa2a39126d360af6c4,Self-supervised Learning for Single View Depth and Surface Normal Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$d77d5c4c55a223512460793669f3016a4efb37db
3fa0505c05d51b4de12d01b181fc366a4ba89eee,2D-to-Stereo Panorama Conversion Using GAN and Concentric Mosaics,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
058623b97e8b400bf3dfd77845e099c09b00d3be,Efficiently Annotating Object Images with Absolute Size Information Using Mobile Devices,d77d5c4c55a223512460793669f3016a4efb37db
feff2a11275768e910942f920321c0f0ac562c14,Super-Resolution for Monocular Depth Estimation With Multi-Scale Sub-Pixel Convolutions and a Smoothness Constraint,cddd92203c8deb022a29b512b11050da531c5f3b
77adcfb70208e79c35080665a4385fe444c0acc2,Soft Rasterizer: Differentiable Rendering for Unsupervised Single-View Mesh Reconstruction,3635881d5632816df7762f2c588138c0baa339ef
658cb9b57be2e2ab1556b423b545ff0b30fec157,Sparse2Dense: From Direct Sparse Odometry to Dense 3-D Reconstruction,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
8283dc86829b0d332da9d7e52f68dcd22e90c850,SfMLearner++: Learning Monocular Depth & Ego-Motion Using Meaningful Geometric Constraints,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
2bf9aa0efed242697efcc8e475eba5c00fc2c5ee,SIGNet: Semantic Instance Aided Unsupervised 3D Geometry Perception,cddd92203c8deb022a29b512b11050da531c5f3b
1992831a6c1cd0e6c7c2a04cbf2f7887be4328e2,"Unsupervised Learning of Monocular Depth Estimation with Bundle Adjustment, Super-Resolution and Clip Loss",cddd92203c8deb022a29b512b11050da531c5f3b
17b771b0e79b80cd4d578bbf7a088d766cdef8aa,Automatic Depth Estimation from Single 2D Image via Transfer Learning Approach,5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
d8e229d7b1e0c8d8459efa59b08610afd7922d8b,Feature-Level Fusion using Convolutional Neural Network for Multi-Language Synthetic Character Recognition in Natual Images,cddd92203c8deb022a29b512b11050da531c5f3b
0eaf62f878d9238dcabab335c923d91c5906d524,Recovering Depth from a Single Natural Image Based on Edge Blur Estimation,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
53b93f30cf673a045ef8eff236be1de3defb1e69,Spatio-Temporal Road Scene Reconstruction using Superpixel Markov Random Field,5f985b914756155c92ebf474409be176bc1a84b4
64cf367c148f23ae051f076c62fb6fe504a2d197,Spatio-Temporal Road Scene Reconstruction using Superpixel MRF,5f985b914756155c92ebf474409be176bc1a84b4
12c5179c88f6ebf42a5b965a7440461ff67eaed8,Double Refinement Network for Efficient Indoor Monocular Depth Estimation,ae89592317675c9c7642a3976c3a064cef736f92
5add1a183d88a5153218ea92a0b9f2dcc14d9a04,DSCnet: Replicating Lidar Point Clouds With Deep Sensor Cloning,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f35941abd1dfe440d1cbe028a3f7fe0d075a734a,Efficient Depth Image Reconstruction using Accelerated Proximal Gradient Method,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
4828ed0c4c93fa45acbc9a3754c6602b91b14868,Contributions to deep learning methodologies,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
ba5c19a02696029566b9e01f5f55e908d25763bd,Every Pixel Counts ++: Joint Learning of Geometry and Motion with 3D Holistic Understanding,cddd92203c8deb022a29b512b11050da531c5f3b
b9eaf37b434b2ffa2b8d7f575cddbb94adb1cac1,FarSight: Long-Range Depth Estimation from Outdoor Images,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f1bbf671510c7dfc6f90a078a509d7bc9eb20176,On Regression Losses for Deep Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
bdb07b76a9f6b5da5ddff292a7bbcf99ca94f159,Stereo Generation from a Single Image Using Deep Residual Network,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$3635881d5632816df7762f2c588138c0baa339ef
1de522d20f53fb271ab5e2a8c35389be0de14e84,Sparse-to-Continuous: Enhancing Monocular Depth Estimation using Occupancy Maps,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
ec8bbf7e3d675a2f9a66e82b03155e57cce8cebf,Photo-based Multimedia Applications using Image Features Detection,d77d5c4c55a223512460793669f3016a4efb37db$$@$$787827850b614135f6b432603afc90b58a8cc665
66b37797286952e7735901e152b4cdea171e8567,Recovering 3D Planes from a Single Image via Convolutional Neural Networks,5ea3e6ef1012b9e7f39451364d68312595b544b8
8670fea0d92c6a0e767d089083a39d5896db8534,"Monocular Depth Estimation with Affinity, Vertical Pooling, and Label Enhancement",cddd92203c8deb022a29b512b11050da531c5f3b
9aeab6393b95ae5f38ed2f77c98cfce705ed572a,Visual Relationship Prediction via Label Clustering and Incorporation of Depth Information,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
53fa7523a647c5c563695f0fecb9360def529b6e,Learning structure-from-motionfrom motion,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
19a84f6713a153e78aaf37235170bc069c7375fc,2D-to-3D conversion using optical flow based depth generation and cross-scale hole filling algorithm,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
4e69dc3d70cbedfb24d421094ffde79f3ac8b1b5,Deep Depth from Defocus: how can defocus blur improve 3D estimation using dense neural networks?,cddd92203c8deb022a29b512b11050da531c5f3b
40608ad557f4aad22db55b1ea3e2e337fd53ba8e,Structured Adversarial Training for Unsupervised Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
179405bfc87e4a4fcfbbeb545bc6be30b436207d,Example-Based 3D Trajectory Extraction of Objects From 2D Videos,4081e007d7eced95cc618164e976a80d44ff5f4e
837f3533ff4d7788251245e090bc8cc3bd9591c4,Detail Preserving Depth Estimation from a Single Image Using Attention Guided Networks,cddd92203c8deb022a29b512b11050da531c5f3b
4f19d33e808a6675f11fb624499d303368deafa1,Learning Monocular Depth by Distilling Cross-domain Stereo Networks,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
1f06651fc5ce2c10cb1f4ad53dd9c931ceb66448,Eliminating the Blind Spot: Adapting 3D Object Detection and Monocular Depth Estimation to 360° Panoramic Imagery,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
c582ace099b9f53cd0a12af1c33dd7f67edf7a9b,T2Net: Synthetic-to-Realistic Translation for Solving Single-Image Depth Estimation Tasks,3635881d5632816df7762f2c588138c0baa339ef
1d1d94a59f952f481ca97024dec444228cbdd7bb,Spindle-Net: CNNs for Monocular Depth Inference with Dilation Kernel Method,3635881d5632816df7762f2c588138c0baa339ef
e958ec7c8931606c7ab51173e602896864f14e68,Domain Translation with Conditional GANs: from Depth to RGB Face-to-Face,cddd92203c8deb022a29b512b11050da531c5f3b
ead93f252a650c79475264b7a1e128d52d81eb7a,Geo-Supervised Visual Depth Prediction,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
329372f397813bed23ae53106886fb3f5f7ebeaf,Automatic Learning based 2D-to-3D Image Conversion,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
b9ca3db76702111955ff583527fa40e0a157b796,Unsupervised Adversarial Depth Estimation Using Cycled Generative Networks,cddd92203c8deb022a29b512b11050da531c5f3b
1ceadfb4a0b6d9893ff9ad7e422299f55485b174,High Quality Depth Estimation from Monocular Images Based on Depth Prediction and Enhancement Sub-Networks,cddd92203c8deb022a29b512b11050da531c5f3b
339a899013324917fbdccdc614e89582abf2f6ab,Layered Scene Models from Single Hazy Images,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$3635881d5632816df7762f2c588138c0baa339ef
605fd3bb51ba37b4ebc14e8d182740e8849e5f74,Less restrictive camera odometry estimation from monocular camera,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
3dc8992dfe0631afd04058eab1eabe1ac752e8ba,Scene Depth Estimation Based on Odometry and Image Data,49531103099c8d17ea34eb09433688e84de4f35f$$@$$a61de626cd5c949baa47f06ac1a864cfaca67ad5
4ba326228728c7ea03a4de6778d0b428b035d5cd,BA-Net: Dense Bundle Adjustment Network,cddd92203c8deb022a29b512b11050da531c5f3b
4597bd719691521a35faca0601ad4caef0abd6ac,Synthetic depth-of-field with a single-camera mobile phone,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
4be966c0846db96dad2f22587f40f3ed566db768,Digging Into Self-Supervised Monocular Depth Estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
58e39ad51611014df3557b88d89aed6cc1e87e76,Monocular Depth Estimation With Augmented Ordinal Depth Relationships,cddd92203c8deb022a29b512b11050da531c5f3b
9c39e9522f13fa3a9549a97a3850601386ff0de2,Monocular Relative Depth Perception with Web Stereo Data Supervision,cddd92203c8deb022a29b512b11050da531c5f3b
21547e038b383fb9d2ca14eb9978b1d4d8e6b178,Real-Time Monocular Depth Estimation Using Synthetic Data with Domain Adaptation via Image Style Transfer,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
63b059cdad77906ff381515b3cfac21757e5e64c,Deep Ordinal Regression Network for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$787827850b614135f6b432603afc90b58a8cc665$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
6a77a59257442da152f4e90729f483018659b7ef,Single Image Dehazing via Conditional Generative Adversarial Network,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
828fd2d8990aca8d7b690ea3d696981a06c94ae4,Learning to Generate Facial Depth Maps,cddd92203c8deb022a29b512b11050da531c5f3b
b273e871b5a49923133e5dd1efe2fa0556eae2b1,An investigation of micro aerial vehicles (µAV),cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
ef1d48feca1b4589e4dfa607e06e23f84d09d967,Recurrent Neural Network for Learning DenseDepth and Ego-Motion from Video,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
b2b8186177c3845f62ca4fe63dc9b1101c1a0064,Deep Monocular Depth Estimation via Integration of Global and Local Predictions,3635881d5632816df7762f2c588138c0baa339ef$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
6cfa4ab327d42103195cb8e5c6181028cec8ee62,PAD-Net: Multi-tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing,3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
ba2e6dddf14fb5facef8e2cbbe845ed7bd26c462,Evaluation of CNN-based Single-Image Depth Estimation Methods,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
3395de3126d9b6b9d75f0d85d8c4ebab8ff84686,MegaDepth: Learning Single-View Depth Prediction from Internet Photos,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
a84e784109e0777393ae4344668b3e3d041666ff,Depth estimation from a single 2D image,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
1231e9ea7fe18e8d6cc7fd0b0285c3644b5e9bed,Structured Attention Guided Convolutional Neural Fields for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
bb288a5c653659411f95ef5db8e1ad652e0a8173,Learning Depth From Single Images With Deep Neural Network Embedding Focal Length,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
9766552d5d25519ed50bcafaf88b7701d2533477,Deep Depth Completion of a Single RGB-D Image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
ba1c60f563629192e8e4f2251e52509e8111c028,Visual Navigation Using Projection of Spatial Right-Angle In Indoor Environment,fdcde62b781ab7bd60aa76d4ec7328fbf9ab7c71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
d97c4da8cbc6b3c5de06eb457acfdf5c7241a522,Monocular Depth Estimation by Learning from Heterogeneous Datasets,4081e007d7eced95cc618164e976a80d44ff5f4e
02c2ba964d9bda503a0da8be212b868d67559c84,Collaborative Deconvolutional Neural Networks for Joint Depth Estimation and Semantic Segmentation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
f031d9319a53a7c95b410d214ff1b37c27f7f08a,Self-Supervised Monocular Image Depth Learning and Confidence Estimation,3635881d5632816df7762f2c588138c0baa339ef$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f58592051db1f5d300d096f2cd7869258d2de9d8,Unsupervised Learning of Monocular Depth Estimation and Visual Odometry with Deep Feature Reconstruction,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
d85dd968c8e56740532e406854911c5a4554d226,Automatic Depth Extraction from 2D Images Using a Cluster-Based Learning Framework,3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
c9d53a2d5c543f5a9bda6b3a5437d5ae5ad14b43,Single View Stereo Matching,3635881d5632816df7762f2c588138c0baa339ef$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
6323db5f1281376029714b51f876d58dd4abd4d0,AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b
f08f76b54c1b6ac1c760f0d9389e6eeb1ce8204a,Monocular Depth Estimation Using Multi-Scale Continuous CRFs as Sequential Deep Networks,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
e92855e7f939c0b43bb4e14e932b6ed4e9312259,Single-View 3D Scene Reconstruction and Parsing by Attribute Grammar,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$88da9026bbedf408aec54b158b456627818cacf9
8608d2789f7d2bf86de9639c4bb502f675123922,IM2HEIGHT: Height Estimation from Single Monocular Imagery via Fully Residual Convolutional-Deconvolutional Network,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
661a3154629fda2361a738d32d305fd8e923900c,Human pose estimation using convolutional neural networks,cddd92203c8deb022a29b512b11050da531c5f3b
3c62cefb474b4725fe3ab63221f80d029257b211,Single-View Reconstruction using orthogonal line-pairs,1f4789a2effea966c8fd10491fe859cfc7607137
e5f803e055a3916d3915c2c19a1773d0dab08844,An evaluation framework for auto-conversion of 2D to 3D video streaming using depth profile and pipelining technique in handheld cellular devices,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
27ccd5200ce03a27c3cecc37f207b42a5e54574b,CANDY: Conditional Adversarial Networks based End-to-End System for Single Image Haze Removal,cddd92203c8deb022a29b512b11050da531c5f3b
ccc65f7744c26dd5d6d7917f23f9392669681be1,"Towards scalable, multi-view urban modeling using structure priors. (Vers une modélisation urbaine 3D extensible intégrant des à priori de structure géométrique)",5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
856f3ba66ac0df55a4b310774809c4f15797d692,Techniques for depth acquisition and enhancement of depth perception,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$3635881d5632816df7762f2c588138c0baa339ef
d74a576cc311841c3ff8070262e928c090e41f59,Shape from Shading Through Shape Evolution,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
81112cd8ec14d7b13673bea833448de611060648,"Factoring Shape, Pose, and Layout from the 2D Image of a 3D Scene",ae89592317675c9c7642a3976c3a064cef736f92
805d089bedc5b4694c844d1eed02897d0eb3f9a2,Depth estimation for outdoor image using couple dictionary learning and region detection,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
a1226b012ad7f204ab851bcb9f24c7ae82a7a8b9,Quantitative evaluation for dehazing algorithms on synthetic outdoor hazy dataset,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
e23222907f95c1fcdc87dc3d3cd93edeaa56fa66,MarrNet: 3D Shape Reconstruction via 2.5D Sketches,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
7208977440bb0e3f17b85c1e1ae24875a2b4ddd5,PanoTrace: interactive 3D modeling of surround-view panoramic images in virtual reality,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db
d84d2d71fca577b6d3b499c93175fac036f417ba,Depth “prediction” using modified deep convolutional neural field,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
1141d7986dea806d04572502b706bcc3ebd29994,SuperDepthTransfer: Depth Extraction from Image Using Instance-Based Learning with Superpixels,1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
22aa73243e6176e7a64f771710a0dcdd5dd141f2,Using Learning of Speed to Stabilize Scale in Monocular Localization and Mapping,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
c0956cc81acd6cb473c35c448636dd5dfd142b18,Diabetes60 — Inferring Bread Units From Food Images Using Fully Convolutional Neural Networks,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
b0f513aa41b5aeb9384f7375fbbf2030be526a93,GeoPose3K: Mountain landscape dataset for camera pose estimation in outdoor environments,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
d442ec9aec47800eb7e48bc387481b5da9f4dec3,Scale Recovery for Monocular Visual Odometry Using Depth Estimated with Deep Convolutional Neural Fields,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
99417afe92b412e3f6a8e344207ec44f468ca0ab,Conditional Regressive Random Forest Stereo-Based Hand Depth Recovery,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
ae8ba2a534b2b23d06dc2b11d708f0b021253b2c,Less restrictive camera odometry estimation from monocular camera,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
483f26c0651bf9f57ce231293736ec5c4e6f54d2,Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image,cddd92203c8deb022a29b512b11050da531c5f3b
accd53443dac63619ae58d4ef01b44539ec68a43,Single image depth prediction using super-column super-pixel features,cddd92203c8deb022a29b512b11050da531c5f3b
2b6d133017f1c2c2540b59a447ef4b5b2135fa5c,High resolution depth reconstruction from monocular images and sparse point clouds using deep convolutional neural network,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
161f820bab8317c72c3feffcbd4578e464e38ebe,GeoCueDepth: Exploiting geometric structure cues to estimate depth from a single image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
3139274bde7a0b8067a2cac6557bfc5e552872ef,Multiple depth layers and all-in-focus image generations by blurring and deblurring operations,3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
d8362cfcf1728ca6b19577aae516825b06f834d3,Depth estimation from single monocular images using deep hybrid network,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
4f663b05fa1214c39adff32a88ba50838f05cb3a,A Compromise Principle in Deep Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$787827850b614135f6b432603afc90b58a8cc665$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
90c80317fa68784a3fe4fc3136bb188895b09fa4,Sparsity Invariant CNNs,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
678ada59855430aa5ef8fa4b623f308ef95746fb,Learning to Synthesize a 4D RGBD Light Field from a Single Image,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
88ed0c362e21ca11758b2779547e211f454510ba,Monocular Depth Estimation with Hierarchical Fusion of Dilated CNNs and Soft-Weighted-Sum Inference,49531103099c8d17ea34eb09433688e84de4f35f$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
d95a2461a6dc20190fc32083a23f2abde1781ccf,Relative Depth Order Estimation Using Multi-Scale Densely Connected Convolutional Networks,cddd92203c8deb022a29b512b11050da531c5f3b
694fa8ad203ef75c9b643cef08c4704a41bfec39,Advanced pattern recognition from complex environments: a classification-based approach,c4b3896b4fbfaeb53d4babf4c856fab14f0601e4$$@$$5171d370a6bb92a5294a6061f1de69eb0e956221$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$a1466825412cdec8f853edf14d95de4c5edc0510$$@$$5f985b914756155c92ebf474409be176bc1a84b4
d0a07dca06b56b238616f98f7d1a45cf6c3632fb,Estimating relative depth in single images via rankboost,5f985b914756155c92ebf474409be176bc1a84b4$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
8906112a968167e844d642e56405a5c5d4d5997d,Interactive High-Relief Reconstruction for Organic and Double-Sided Objects from a Photo,ae89592317675c9c7642a3976c3a064cef736f92
14459091b9a3b49cf60ef4f28084cffd0afe73b7,UltraStereo: Efficient Learning-Based Matching for Active Stereo Systems,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
19808134b780b342e21f54b60095b181dfc7a600,SIFTing Through Scales,cddd92203c8deb022a29b512b11050da531c5f3b
2935e944f1c2471e4249053effba1adaf7c019f9,Development of methodology for depth estimation for images and videos,acf0b6745708457a53d5327eea345c0bcf466e97
78aa0cd57548fae58be1d411da55cb54bd3544a6,Depth Map Design and Depth-based Effects With a Single Image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db
e6dda50d48abf0a4cb4cdcf3c47cc23ddc2b5c1c,Probabilistic Global Scale Estimation for MonoSLAM Based on Generic Object Detection,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
0473426a7206822e47ae719f984a555a14c0089c,Temporally Consistent Depth Map Prediction Using Deep Convolutional Neural Network and Spatial-Temporal Conditional Random Field,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
787aee1d59b347fe08b68f3def33b505c6a7e624,Real-time ground marking analysis for safe trajectories of autonomous mobile robots,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8
3c11aa724ee517f445fcea2df615d3c5d5b662de,Static Scene Illumination Estimation from Videos with Applications,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
b3e100ca27c71f337f1872e3f9d28585cf573ed3,Bayesian depth estimation from monocular natural images.,5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
03a7d2aa06dd7accfe7d24d08cdcb6af22dfac00,Multi-scale Continuous CRFs as Sequential Deep Networks for Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
4824372697c859b3081228a278da0e4e24f32a4a,Stereo reconstruction using top-down cues,49531103099c8d17ea34eb09433688e84de4f35f$$@$$a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$431759eaf743bf4ad35ae9aab9fcc1b7469505b6
2aaa2de300a29becd569fce826677e491ea0ea70,Learning Category-Specific Deformable 3D Models for Object Reconstruction,"For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
d081a901214529e4103bfe36c9e91a620ebb30a7,Depth Estimation by Parameter Transfer With a Lightweight Model for Single Still Images,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$3635881d5632816df7762f2c588138c0baa339ef
4a139521bf6ad8e31ceffba26e95a819f961d511,Efficient edge-aware surface mesh reconstruction for urban scenes,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$e36632f52c995e28896fa0663c39ae345d097da6$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
17981035fe7c5d901b5662abe55ca5fd8b7f6d45,An Intelligent Body Posture Analysis Model Using Multi-Sensors for Long-Term Physical Rehabilitation,3635881d5632816df7762f2c588138c0baa339ef
25e30c21d1891fcfcc0533f12d23f55bccb53ecc,"Patchwork Stereo: Scalable, Structure-Aware 3D Reconstruction in Man-Made Environments",a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
e32a51547f8d88b644346629a5d455897c64fc02,Geometry-Based Region Proposals for Real-Time Robot Detection of Tabletop Objects,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
444d5f8d75958038e9f925a0b64e4a797199eac6,Semiparallel deep neural network hybrid architecture: first application on depth from monocular camera,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
1007da6045bda6ea81f5269618fc8ec6480d960c,Thermal image colorization using Markov decision processes,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
f06019daf85ce6f592b9a3e6af1d56bff7d5e792,Analyzing modular CNN architectures for joint depth prediction and semantic segmentation,cddd92203c8deb022a29b512b11050da531c5f3b
ba450759e9385efe3ecfa57a9676c3a4bcd47340,Development of Semi-Automatic Methodology for Extraction of Depth for 2D-to-3D Conversion,acf0b6745708457a53d5327eea345c0bcf466e97
bcf3b0b06908b86d46de618ba21e7ee025f71b45,RETRACTED ARTICLE: Image retargeting based on self-learning 3D saliency for content-aware data analysis,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
6088a5af7198e763f9d6a9a5e78f45302228a3ff,Semi-Supervised Deep Learning for Monocular Depth Map Prediction,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
a924950dc13ef5dafce1eba19578dca786275241,Development of methodology for extraction of depth for 2D-to-3D conversion,acf0b6745708457a53d5327eea345c0bcf466e97
1295b038ac6903b0ad2cee280bc8ebbf4590e943,Toward Domain Independence for Learning-Based Monocular Depth Estimation,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
2d78df57ad2afcd5cd488297c132e87d38bd5b9f,3D Reconstruction of Simple Objects from A Single View Silhouette Image,5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$d77d5c4c55a223512460793669f3016a4efb37db
68124909aa40286f545e934efffbed240032931a,Indoor scene modeling from a single image using normal inference and edge features,3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8
d49d2f13f2ce692b8263b30511edc163264eaca6,Regressing Robust and Discriminative 3D Morphable Models with a Very Deep Neural Network,5b1dcc50c7c23468f3a53226fb57fdd3e5993113
84624c837102997784ce630b392d0975b642a4db,DeMoN: Depth and Motion Network for Learning Monocular Stereo,cddd92203c8deb022a29b512b11050da531c5f3b
41d08fb733f3e50ac183490f84d6377dffccf350,A Point Set Generation Network for 3D Object Reconstruction from a Single Image,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
f7e91701ca7db1d9de3e8a1d082e2cf0cbbda7a5,Automatic 2D-to-3D image conversion using KNN search,cddd92203c8deb022a29b512b11050da531c5f3b
089d11afc46c35b46f79fd00f7c3666315befbde,Single image depth estimation using joint local-global features,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
0b6a100f939b276ee1663e6b619a42dbec6ddefa,2-D to 3-D conversion of videos using fixed point learning approach,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
00d793b0c383f3232ba96b73d6917925ebb75ebe,Single-View and Multiview Depth Fusion,49531103099c8d17ea34eb09433688e84de4f35f
aec6f5756d96c4194b6f4ea81eeaa3404bd754b7,Fast depth extraction from a single image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
3af4102df04bf62bcac5d5cf3924d68a3c2ec447,Joint Depth and Semantic Inference from a Single Image via Elastic Conditional Random Field,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$3635881d5632816df7762f2c588138c0baa339ef
62ba4cc1657237ee3b4ac9d23cc8a0b978e264e8,A novel 2D to 3D video conversion system based on a machine learning approach,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
b174d5773d8eb6e992d65e12f6fce051beadc35c,Object Depth Estimation from a Single Image Using Fully Convolutional Neural Network,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
51f1e41d7c2a5d999e2a58f05319f4b1e7dd4877,Parse geometry from a line: Monocular depth estimation with partial laser observation,cddd92203c8deb022a29b512b11050da531c5f3b
806d7b97c3535a3c62ce243fe7008149062d14c1,Learning to Count with CNN Boosting,cddd92203c8deb022a29b512b11050da531c5f3b
a4bfc7436272926d4e433b4e425b2d5aa61227dc,Exploiting Depth From Single Monocular Images for Object Detection and Semantic Segmentation,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
1d2e33bad29c525a16b2f6651360de6eef45cd1c,Spatial layout and surface reconstruction from omnidirectional images,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4
32af09049f16b2aa47f00592e3241763fe2ce4bd,Pano2CAD: Room Layout from a Single Panorama Image,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8
2540699ddec7aededb6ac589de0d9afcfa7a8d10,An improved genetic algorithm for three-dimensional reconstruction from a single uniform texture image,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d,Unsupervised Monocular Depth Estimation with Left-Right Consistency,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
dafbc15be7fb3ab3586d296563f1964d328ff546,Survey on Recent Progresses of Semantic Image Segmentation with CNNs,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
fb1ba17ef321162fb38dec7a9a7a411458fbf0f2,Rapid learning-based video stereolization using graphic processing unit acceleration,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
3fecbad2544e81138c7f6203c56c88f13ece4fd0,Quality assessment of monocular 3D inference,5ea3e6ef1012b9e7f39451364d68312595b544b8
20bb659ab2f702bb3cf053616af3cd10f0df1d51,Normal Guided Data-Driven Semantic Modeling from a Single Indoor Image,3635881d5632816df7762f2c588138c0baa339ef$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$d77d5c4c55a223512460793669f3016a4efb37db
a6450b4edc8ed13a8301a0fecbd812514f0954f0,Stereoscopic view synthesis based on region-wise rendering and sparse representation,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
5e04993131589e6d3d6d601287400856702a6a4a,Three Dimensional Reconstruction from Single Uniform Texture Image with Unknown Lighting Conditions,3635881d5632816df7762f2c588138c0baa339ef$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
004c5382f012a941fa8f071444b3abe96f0e5d74,Multilayer cognitive architecture for UAV control,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
2ff959e64cd6db514f37a8df4a68955d6bf5f669,Unsupervised Structured Learning of Human Activities for Robot Perception,cddd92203c8deb022a29b512b11050da531c5f3b
6ca1a06cd0019d1b48c7c603536b31622928b01d,Fast depth estimation from single image using structured forest,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
1ded9614426b721739adfa6088c1f50b6e543af2,Highlighting objects of interest in an image by integrating saliency and depth,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
8e2091f4c9ee8aa58a6d653ab32ff3a80f1625a0,Automatic segmentation of multimodal brain tumor images based on classification of super-voxels,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
344e99659aa1a705b17dc82cad69ac36f8d6b843,Fast robust monocular depth estimation for Obstacle Detection with fully convolutional networks,421e6c7247f41c419a46212477d7b29540cbf7b1
846b35459dd57bc3aee85eb209e97fc180c0cbec,A Two-Streamed Network for Estimating Fine-Scaled Depth Maps from Single RGB Images,5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
dae51eb485f3669e184b9689fb9dbfb933769dc3,Monocular Depth Estimation Using Neural Regression Forest,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
0b7265af8a100676bc168dcd4584d6609e56e739,HyperDepth: Learning Depth from Structured Light without Matching,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
2e54616134fab15928da19193e0d6dac9744dabe,Multi-modal Auto-Encoders as Joint Estimators for Robotics Scene Understanding,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d77d5c4c55a223512460793669f3016a4efb37db
4f71a160138d1a1f2db97dacc56106d62b208202,Depth estimation from a single image in pedestrian candidate generation,787827850b614135f6b432603afc90b58a8cc665$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$1300162100517d5b1c8089a5a3c0f65106400833$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
2f7ae3361b2aafa24fc289252a9cad8f1135edae,Deeper Depth Prediction with Fully Convolutional Residual Networks,ae89592317675c9c7642a3976c3a064cef736f92$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
9b97b96cf2762197f6a34559fb5b88dc176d0709,Single Image Object Modeling Based on BRDF and r-Surfaces Learning,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
5494d9e1283f49af45153c959f1161830d491430,A study on the effects of RGB-D database scale and quality on depth analogy performance,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
ad910873f906029715ffff1f9eff341260ececd9,Structured Regression Gradient Boosting,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
1cec5961a8fc98cf700500acb38b7aae8223aaa4,Modeling Photographic Composition via Triangles,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4
197560e46256b3749ac654666e0e6eb1ad728afb,Thermal image colorization using Markov decision processes,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
2c9aab3a26a1396b997419c44e5774fe913a0d40,Real-time 3D scene layout from a single image using Convolutional Neural Networks,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
d27c6800894441054685ffdf896fab15cebf5fd6,Estimating Depth From Monocular Images as Classification Using Deep Fully Convolutional Residual Networks,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
70b82a903d31eeb2098dcdcc74440a40b5ec2790,Fast compressive measurements acquisition using optimized binary sensing matrices for low-light-level imaging.,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
400eb5386b13c32968fee796c71dec32aa754f1e,Synthetic Data for Text Localisation in Natural Images,ae89592317675c9c7642a3976c3a064cef736f92$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d77d5c4c55a223512460793669f3016a4efb37db
b17e61972e674f8f734bd428cb882a9bb797abe2,Single-Image Depth Perception in the Wild,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
37808f671207757d63803bd8e13766cc19c17a48,GAL: A global-attributes assisted labeling system for outdoor scenes,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4
be906dc15b9143e8ae1372248930b492db09a2d9,2D-to-3D Conversion System using Depth Map Enhancement,3635881d5632816df7762f2c588138c0baa339ef$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$02afb3629ac3585b51b914e306ed59bd33448b03
a48c4c6707fca20ae64b044b6e8f7f37891186fc,Persistent self-supervised learning: From stereo to monocular vision for obstacle avoidance,3635881d5632816df7762f2c588138c0baa339ef$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
94b231a56f7021ec9304a35973510ba108253e2c,Depth estimation from single images using modified stacked generalization,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef
c066b2711811697ede2d5813b582233e9d8763df,Dealing with small data and training blind spots in the Manhattan world,4081e007d7eced95cc618164e976a80d44ff5f4e
3d4f5b42fd9d646c1f7db14820e33b1e7a18c4e0,Understanding People from RGBD Data for Assistive Robots,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$6a4300efb6895695205dfc1b74e124f9fea6aff2$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
46577e565d3ba8a667c627a1004aacbae17d59ef,Modeling the environment with egocentric vision systems,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
52339ee8e4d3422f722b13f3ce44d5e09d7951b7,Learning depth from a single image using visual-depth words,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
0da0a5158e1dab17e8973d9ed2b25acf093409fd,Learning-based depth estimation from 2D images using GIST and saliency,cddd92203c8deb022a29b512b11050da531c5f3b
a5c02bec9755dbe59696e80ec550a2e0966508c4,Scene Intrinsics and Depth from a Single Image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
79f9029e31fd19e162ae3775dbac01975cfe42cf,Intrinsic Depth: Improving Depth Transfer with Intrinsic Images,3635881d5632816df7762f2c588138c0baa339ef$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
87992194ccaa0f7e2f2699c618053f0e168f9d3f,A novel algorithm for shuttlecock tracking,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
88a603599b1df39213a88ba5565609c0170576bc,Depth estimation from single image using Defocus and Texture cues,cddd92203c8deb022a29b512b11050da531c5f3b
2128120c71ef78267c630534cd098a74d3e8a6d6,Learning human photo shooting patterns from large-scale community photo collections,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
3e159fed0fa7dd8f1c8d24c56ce3fc3ff9f16831,DOC: Deep OCclusion Estimation from a Single Image,83fa51c8ca9144361d4ba26152e7cfa27d5c5649
a4d9f1cec4b920126da60a0cf011740b9a27f275,DOC: Deep OCclusion Recovering From A Single Image,83fa51c8ca9144361d4ba26152e7cfa27d5c5649
1cf220df37a9c5e1fd57a5046cfb9513abba9b27,Structured Depth Prediction in Challenging Monocular Video Sequences,ae89592317675c9c7642a3976c3a064cef736f92$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
5ea88cf07072e5fb4495e72642147477a6406a4c,A depth estimating method from a single image using FoE CRF,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$3635881d5632816df7762f2c588138c0baa339ef
3731ba07aa14d88a17c1bb3f847ddcd639047185,Depth Analogy: Data-Driven Approach for Single Image Depth Estimation Using Gradient Samples,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
973321a7d943d0608b36e4c3a97f22c81e74d0e9,Plane Extraction for Indoor Place Recognition,ae89592317675c9c7642a3976c3a064cef736f92
722fc7605bb2bf0772c7988cd0e1068fccd4f8a5,Break Ames room illusion,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
7a5515fbd084c8416bc3c7507d75d8aed49d2c97,Learning objects model and context for recognition and localisation. (Apprentissage de modèles et contextes d'objets pour la reconnaissance et la localisation),a31e9d09d90261fc68acffe097df592cfdcb7706
25f308a971b5c5835c0d724c300ddfbb16b31d97,Persistent self-supervised learning principle: Study and demonstration on flying robots:,3635881d5632816df7762f2c588138c0baa339ef$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
dcf5c69481c72b271eba098842e172ec1441b41a,Utilización de técnicas de clustering para mejorar la detección de meta-topics en conjuntos de datos extraidos de Twitter,5f985b914756155c92ebf474409be176bc1a84b4
5a3e3b22c30b53c03f46805b3f20980b6376a2ef,Recognising Planes in a Single Image,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
7d78241bcc3bc3bd952e89e3157058997c1f8067,Hallucinated Humans: Learning Latent Factors to Model 3D Enviornments,3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$a1466825412cdec8f853edf14d95de4c5edc0510$$@$$2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
8cfb50e6e02cdfb35b0c1571039b41eb6a6b64bf,"Shape, Illumination, and Reflectance from Shading",86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
54f5361bcdc9a471b2e3ee04663c905f3d6bec99,Edge-based depth gradient refinement for 2D to 3D learned prior conversion,cddd92203c8deb022a29b512b11050da531c5f3b
2440359e54a134e500f00eef98276378c17983d5,Parameter Estimation and Energy Minimization for Region-Based Semantic Segmentation,ae89592317675c9c7642a3976c3a064cef736f92
73c8acd433c33e09916eaa1b0311c3ea7b2610d2,Deep Stereo: Learning to Predict New Views from the World's Imagery,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
7916b7366c761483222ed8db4a4f18fb098874ec,A Classification-Based Algorithm for Building 3D Maps of Environmental Objects,c4b3896b4fbfaeb53d4babf4c856fab14f0601e4$$@$$5171d370a6bb92a5294a6061f1de69eb0e956221$$@$$a1466825412cdec8f853edf14d95de4c5edc0510$$@$$c99f2391b956dc189855541e49e53c21ae5ec603
39992cd1ef24960d34b7867663acf17be25345f2,Extracting 3D Trajectories of Objects from 2D Videos using Particle Filter,3635881d5632816df7762f2c588138c0baa339ef
ee80688bc361b114109b8e18c3446f0d4fe5ee1f,Object detection and depth estimation for 3D trajectory extraction,4081e007d7eced95cc618164e976a80d44ff5f4e
3c9ab02fa6b883c3b6f53b0332acf221ef1fa809,Depth and surface normal estimation from monocular images using regression on deep features and hierarchical CRFs,49531103099c8d17ea34eb09433688e84de4f35f$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
c671825caa9dd2e36f99a4a40d560438a45993f7,Holistic 3D scene understanding from a single geo-tagged image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e
0a659360a41ac3fbe535463db90c32e1c697c69c,Fast 2D border ownership assignment,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649
ff7c25a48e297a9552a4a472cf2f35017328d19e,Displets: Resolving stereo ambiguities using object knowledge,49531103099c8d17ea34eb09433688e84de4f35f$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
ca0c3f565960aa768c3635d922ac277c8521482d,Indoor scene structure analysis for single image depth estimation,3635881d5632816df7762f2c588138c0baa339ef$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
9425bba8f46dca5d0788a3f6cbfbf13ad207093f,ℋC-search for structured prediction in computer vision,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$3635881d5632816df7762f2c588138c0baa339ef
59f5fb05668fdbec0e62f2a8eb57a599ec0c384f,Direction matters: Depth estimation with a surface normal classifier,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
8b5d6fc8d5fd0751caeecc51661d5380c2da06f2,Superpixel meshes for fast edge-preserving surface reconstruction,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$e36632f52c995e28896fa0663c39ae345d097da6
0044e254db1e94e4df6ead1a63a4152d9decfe3e,Colored three-dimensional reconstruction of vehicular thermal infrared images,1300162100517d5b1c8089a5a3c0f65106400833$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$da9b9ebf674de0a6e26223639410e32e77ce1be1$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
783ede2c10d75a1cbd31a9b9d0ba1226648c7e20,Estimating structure of indoor scene from a single full-view image,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
a32a298c78f22fc855220a2ce667dc1d2b9ec179,Design flow of motion based single camera 3D mapping,a31e9d09d90261fc68acffe097df592cfdcb7706
f2fc0f0cc675f4f2b3d75234e661888711cb17d9,Extracting 3D Layout From a Single Image Using Global Image Structures,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
73491c2c2a47f8e6348868cb99485dff6be645ab,SmartAnnotator An Interactive Tool for Annotating Indoor RGBD Images,5f985b914756155c92ebf474409be176bc1a84b4
d4ed57a698179fb7b1cbe4a3e6e3534871c5e059,3D Reasoning from Blocks to Stability,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
ecde1c993f58a4ebd34aa7033e49f3f964b05fc6,Online self-supervised learning for dynamic object segmentation,a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe
4e4fd5bb9e75bbb9f6726f617f014e96c9d04b68,Monocular Extraction of 2.1D Sketch Using Constrained Convex Optimization,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$0b14178e7d79ac426d0a39700e1ac8b2c6f2e752
6d878ff4f9e004b27e2722880bf5005ada617376,Image aesthetics enhancement using composition-based saliency detection,3635881d5632816df7762f2c588138c0baa339ef$$@$$787827850b614135f6b432603afc90b58a8cc665$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
9c21b3ffdac5f2450b82dd6660ac69f72bb9018b,Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields,cddd92203c8deb022a29b512b11050da531c5f3b
d21bf243042aad508b27d00e1b7909c1d63f2082,Data‐Driven Shape Analysis and Processing,0b14178e7d79ac426d0a39700e1ac8b2c6f2e752$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
e2006287b1d617c15de83ef0da4fb79799fb0f82,Learning multi-planar scene models in multi-camera videos,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
ff7104c34a7400aca20e57cd13695bb20a5dce0b,Specular reflection removal and bloodless vessel segmentation for 3-D heart model reconstruction from single view images,3635881d5632816df7762f2c588138c0baa339ef$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
34d4b0028447a38fc8f46c22232dff340fa4bb84,Toward Naturalistic 2D-to-3D Conversion,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
b8e759d5c2857f2438ee6f551eb9eb30c8e340e5,Coupled depth learning,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
8a6a28e6c7d3006220e98ebf1c8d12008c4edbc1,Depth Map Generation for Aerial Video in Natural Scenery,82ebff86c9f862522d5a78ecac3717243daddd43
e39a5ef2d966b10194784be5bb794b4693b32733,Finding Temporally Consistent Occlusion Boundaries in Videos Using Geometric Context,3635881d5632816df7762f2c588138c0baa339ef$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649
b8633600fa437b37fb6e1b4fd132bd8911c56eee,Variational Regularization and Fusion of Surface Normal Maps,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
0571a7ef57ec0828da12e7639084325119e035e7,3D structure estimation from image stream in urban environment. (Estimation de la structure 3D d'un environnement urbain à partir d'un flux vidéo),4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$787827850b614135f6b432603afc90b58a8cc665
55bb62b383437c202200b63d81c82a56a99334bd,Depth inference with convolutional neural network,cddd92203c8deb022a29b512b11050da531c5f3b
3f25b3ddef8626ace7aa0865a1a9e3dad1f23fb6,Deep convolutional neural fields for depth estimation from a single image,cddd92203c8deb022a29b512b11050da531c5f3b
571f4ab3566769faa349c230070db4d1ab77961a,Virtual view networks for object reconstruction,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
67711d42b77a13a04822ae00620660cef3abf8c4,"Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-scale Convolutional Architecture",cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
6ff0a04761e1a2589d994a99edd7d394d935379c,"On hierarchical models for visual recognition and learning of objects, scenes, and activities",1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
9e360f51f444afd2219878a0b21d151e70cd6ba0,Depth estimation in monocular Breast Self-Examination image sequence using optical flow,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
c360b3e566d0a87997247a0d59a8f5ca3084e40f,DEPT: Depth Estimation by Parameter Transfer for Single Still Images,acf0b6745708457a53d5327eea345c0bcf466e97$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
05ad28e10cf6858bdd18968ef7b70be6e0f985cd,Surface Prediction for a Single Image of Urban Scenes,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$ae89592317675c9c7642a3976c3a064cef736f92
10746c48acb468ac8402b8380a12e6bbe1993b91,3D Spatial Layout Propagation in a Video Sequence,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
ba9e2b0756a83e9bbbea521acd1bf94d318b49db,Depth extraction from a single image by sampling based on distance metric learning,cddd92203c8deb022a29b512b11050da531c5f3b
a00f6a040920c9b53c09385a9f42c92c1d8412e2,Efficient Depth Propagation for Constructing a Layered Depth Image from a Single Image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d77d5c4c55a223512460793669f3016a4efb37db
4359402d3eefdcd43c65a6136c41b2091c82bbf7,Shape-From-Focus Depth Reconstruction With a Spatial Consistency Model,cddd92203c8deb022a29b512b11050da531c5f3b
353758f7f38e1e14e545959bca73f3830c878e4b,Unfolding an Indoor Origami World,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
6359055d6eb9c8e42882397f6b98cf5bf81179c3,3D Layout Propagation to Improve Object Recognition in Egocentric Videos,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
72f3ef4c8904a9c48bbeab2485cc0a7f6fbb0a15,PanoContext: A Whole-Room 3D Context Model for Panoramic Scene Understanding,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8
c221de2dfebb1a536382c8ad8ced3910b872e6d3,Discriminatively Trained Dense Surface Normal Estimation,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
69ceb4d9e36a30e128d3a9660604e39a0eb3296c,Depth Extraction from Videos Using Geometric Context and Occlusion Boundaries,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$49531103099c8d17ea34eb09433688e84de4f35f
55074164a744503e0ff8cff95b20fd6a8699c66f,Estimating image depth using shape collections,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
ca960c0f6fa981070b423eb3390c29882117f47d,Cut-and-Fold: Automatic 3D modeling from a single image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d77d5c4c55a223512460793669f3016a4efb37db
cda3766534c9ceb90cc699c0cac6654ea9aab858,Single Outdoor Image Depth Map Generation Based on Scene Classification and Object Detection,5f985b914756155c92ebf474409be176bc1a84b4$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
f26d8658bca339794c31c4706bec8b1204b3d866,Hierarchical Semantic Labeling for Task-Relevant RGB-D Perception,cddd92203c8deb022a29b512b11050da531c5f3b
1f60e0f74a2f409e906c164baa14684c946f318f,Dense Correspondences across Scenes and Scales,5b1dcc50c7c23468f3a53226fb57fdd3e5993113
ca471ffba0e66773e2fae7971e250b2b82b1e538,Shadow Removal from Single RGB-D Images,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
008bd9247d2664fdcf37efb9742f153c6cadea02,Discrete-Continuous Depth Estimation from a Single Image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$3635881d5632816df7762f2c588138c0baa339ef
1315845cd20204831cb1bc1164a165dc54fb0d70,Single-View 3D Scene Parsing by Attributed Grammar,ae89592317675c9c7642a3976c3a064cef736f92
f431439715628d699275e5cb94d02b61f750d9be,Efficient Structured Parsing of Facades Using Dynamic Programming,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
f3e3341d16f9d499eb2c70d5f652a56a5abc2d70,Semantic Visual Understanding of Indoor Environments: From Structures to Opportunities for Action,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
8674c8d29920345c9a0726bb8c20ce5b9ea021dc,When 3D Reconstruction Meets Ubiquitous RGB-D Images,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
b44c78666956df59eb7b1769c57cf89602a6a1d1,Grounding Acoustic Echoes in Single View Geometry Estimation,4081e007d7eced95cc618164e976a80d44ff5f4e
fdf9c636f79f146f116bbca392dcad3b535cecb2,Statistical Approaches to Inferring Object Shape from Single Images,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
beb63f7272d082505d2c684aca6ed90d33858c4a,Automatic Scene Inference for 3D Object Compositing,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$d77d5c4c55a223512460793669f3016a4efb37db
8d0ed7f092c918e306fd2c92661f92823b336fde,Putting the User in the Loop for Image-Based Modeling,d77d5c4c55a223512460793669f3016a4efb37db$$@$$82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
afc68658553bfb7bf6c265efece16b20bbcdf510,3D Traffic Scene Understanding From Movable Platforms,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700
6b011aa54aeabae8ac172a0cf0dd4333d1bfd327,Supervised algorithm selection for flow and other computer vision problems,a1466825412cdec8f853edf14d95de4c5edc0510$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
5f8f3e0fa482cf38a77af3af08b0375f1c49415a,Depth Transfer: Depth Extraction from Video Using Non-Parametric Sampling,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
55cb0ba0ef122ee2c9010df63f6f6e46eb1aaee5,Temporally consistent semantic segmentation in videos,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
4a76c710ecb7dd2e73500a9fc359a2b7a8ce97de,Combining semantic scene priors and haze removal for single image depth estimation,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
3b3e429d8201394633583620ae582a5471773a43,Color and flow based superpixels for 3D geometry respecting meshing,5f985b914756155c92ebf474409be176bc1a84b4$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649
577ecd2d481f788b391d8fe3cba24334ed6c8bcc,Im2depth: Scalable exemplar based depth transfer,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$f46d387ae28fe61e2e40b2fe012327e9c4b42c03
d7ea08277f20f27a10d81e0b3673b1eab8d87470,SmartAnnotator: An Interactive Tool for Annotating RGBD Indoor Images,5f985b914756155c92ebf474409be176bc1a84b4
8be4b7d8d1a09c05411b2d135fbe1590f11d3798,Object Recognition and Semantic Scene Labeling for RGB-D Data,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
2462a2a271d3113c7186b6995d7cdbe61f870407,3D Scene Understanding: From Segments To Volumes,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
384041d141da28687364972cba67a5403a6196eb,Vegetation detection and terrain classification for autonomous navigation,5f985b914756155c92ebf474409be176bc1a84b4
2c4ea6ea6ab42e228d39eed518f8efe32dd19f69,Which Edges Matter?,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4
c855d8b75090e4d4aadd6ce936046327774470c9,Data-Driven 3D Primitives for Single Image Understanding,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
bb60e7324b384ef0d817d0a90f06475d2a1f906c,Shape Anchors for Data-Driven Multi-view Reconstruction,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$e36632f52c995e28896fa0663c39ae345d097da6
19c860b4b6e6259911b80fae22a80530022b61a9,3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
9d00e7465dcafa40f9e0fa0939aa648184c84b4d,Labeling Spain With Stanford,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
6cf2b67bf414273e81f64f3e48b290de5540c87b,Viewing Real-World Faces in 3D,5b1dcc50c7c23468f3a53226fb57fdd3e5993113
2b5b0e349d832bfdfca932276b99cdbc9855a37f,Estimating the 3D Layout of Indoor Scenes and Its Clutter from Depth Sensors,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
b16c2405a45a9d8cf6e4c8485e0b50ec0a231aea,Semantic indoor maps,ae89592317675c9c7642a3976c3a064cef736f92
16f9f34d4f9e863909e44ae6f1a4d86c64996d82,Efficient Reconstruction of Complex 3-D Scenes from Incomplete RGB-D Data,5f985b914756155c92ebf474409be176bc1a84b4
33bc340be72c821964d9d2d1498fb63072547e3a,Interactive Stereoscopic Video Conversion,a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
517f0211365caa084f93581a04df48c59fbfb53b,A Weighted Color MRF Model for 3D Reconstruction from a Single Image,5f985b914756155c92ebf474409be176bc1a84b4$$@$$d77d5c4c55a223512460793669f3016a4efb37db
83dca499c606661de09da0292404dbaecea2fc0f,3D building modeling using images and LiDAR: a review,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
5be3878c60d02e2ed03be04d9dbcdd1d535b1b63,Single image ground plane estimation,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
cae198be530eebd79cf48c9354660fabc1dc2054,Place recognition from disparate views,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e
549b2c1685c3f74e388dae44fda37a2250c01f68,Adaptive Image Warping for Hole Prevention in 3D View Synthesis,82ebff86c9f862522d5a78ecac3717243daddd43
cf16ec9441fbfdcf0ec811f25a2b804f562c9958,"Object detection, shape recovery, and 3D modelling by depth-encoded hough voting",82ebff86c9f862522d5a78ecac3717243daddd43$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
4b52f70f91d091fa548eb7c864122e53c0014da4,"Learning-Based, Automatic 2D-to-3D Image and Video Conversion",96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
7857d3f48e1e4877ef2c66c106fbf3adf9aed091,Digital Multi-Focusing From a Single Photograph Taken With an Uncalibrated Conventional Camera,5f985b914756155c92ebf474409be176bc1a84b4
0754be0801b5b7a3cb9e4011a8efcf3df8f12bd4,Probabilistic Models for 3D Urban Scene Understanding from Movable Platforms,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$6a4300efb6895695205dfc1b74e124f9fea6aff2$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
21417be81f056623daa953e99ddf37db28d5888e,"Basic level scene understanding: categories, attributes and structures",96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8
c3e5f94a79f0809420127b5b970cf3d275eb71ba,Understanding Humans And Objects Based On Context,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942$$@$$c99f2391b956dc189855541e49e53c21ae5ec603
9a277b5336d27c53b224aa861b2826786a3cf8ac,Efficient automatic depth estimation for video,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
64e38914fa77266b7e0a037c8ffe3a260d219fa6,Single View Reconstruction of Piecewise Swept Surfaces,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
74a08647f3852750b3915567d4f9f76d2f79f959,Intrinsic Scene Properties from a Single RGB-D Image,"For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
57e1cfaa392a82955609994f79a536bb143ccc01,"3D-Based Reasoning with Blocks, Support, and Stability",cddd92203c8deb022a29b512b11050da531c5f3b
2e0f6791a2dbed4dd1185514ae49294e06ac299b,Manhattan Scene Understanding via XSlit Imaging,1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
c0c2e331fea01cc4a30608507a9f0693142169e5,Hallucinated Humans as the Hidden Context for Labeling 3D Scenes,cddd92203c8deb022a29b512b11050da531c5f3b
9d2040554c891236f4637ee177fc2527dc809142,Surface Layout Estimation Using Multiple Segmentation Methods and 3D Reasoning,a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5f985b914756155c92ebf474409be176bc1a84b4
31d574e2e0a8a448580cbd4b95c13594a084bd09,A bag of words approach for semantic segmentation of monitored scenes,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
9b07ba7628d47c262fb47eb682d4a2412ebf9feb,Robust real-time visual odometry for dense RGB-D mapping,cddd92203c8deb022a29b512b11050da531c5f3b
6bf8de22f6d07e91b032d5024c3fbc8d629ca8d7,View Transformation Based on a Single Outdoor Image,ae89592317675c9c7642a3976c3a064cef736f92$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
3f42607589377d7d3a629a42e1058f4e0b4ab3d0,Contextually guided semantic labeling and search for three-dimensional point clouds,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$6a4300efb6895695205dfc1b74e124f9fea6aff2$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
a9f0cde597f7a5563cb17becc9eabe9fd7cf796c,Dynamic visual understanding of the local environment for an indoor navigating robot,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
5ae216a999b5560c550b480d8a8d4d1e8169421c,Low-power parallel algorithms for single image based obstacle avoidance in aerial robots,fdcde62b781ab7bd60aa76d4ec7328fbf9ab7c71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
a41ac28041e7c4f97d36753ec86acfa11ee9f19f,Multiple ground plane estimation for 3D scene understanding using a monocular camera,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
33f2465fd69bfb8ed9172ca40f15154368ac6539,Enabling warping on stereoscopic images,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
e29b85379dbe4ef37df1181f7b30d7f52dd069e7,Object Detection using Geometrical Context Feedback,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4
47b0bf9bcc89f81bb8d989e9d9570dd677b2eae1,3D multimedia signal processing,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
3ec424dade123c3ac4f8bb903d51b51c75ba92b6,Parallel view synthesis programming for free viewpoint television,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
856a0ecf2a2952f5df1f0d0f8faf034550ced6d6,Exploiting Physical Inconsistencies for 3D Scene Understanding,d77d5c4c55a223512460793669f3016a4efb37db
77a198380a3ac0d592b95e4c042e78be4ee86c2e,People Watching: Human Actions as a Cue for Single View Geometry,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe
be68de3170fcc6886383b9f6c6eabeb722f0950e,Combining Monocular Geometric Cues with Traditional Stereo Cues for Consumer Camera Stereo,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
601c37cc3ee946a8f20983df872a62158f70f2e9,Shape from Angle Regularity,ae89592317675c9c7642a3976c3a064cef736f92$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
5f8662a7346b3e2859941766d599dbabd000353c,Patch Based Synthesis for Single Depth Image Super-Resolution,a1466825412cdec8f853edf14d95de4c5edc0510$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
59c24546ea36ef44e1a67bdc294493310391fa74,"Shapecollage: Occlusion-Aware, Example-Based Shape Interpretation",5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8
df028190efdd1e78bb79195b0627670511e9a5fa,Depth Extraction from Video Using Non-parametric Sampling,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f,Learning human activities and object affordances from RGB-D videos,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$5f985b914756155c92ebf474409be176bc1a84b4
62ce203b0f07e049178dc3edf69b1b426cf3f876,Fitting plane algorithm-based depth correction for Tyzx DeepSea stereoscopic imaging,5f985b914756155c92ebf474409be176bc1a84b4
e07f6213406295c4db39ed3dc6ceb4e5f2889a02,3D scene reconstruction and understanding from single shot pictures,ae89592317675c9c7642a3976c3a064cef736f92$$@$$5f985b914756155c92ebf474409be176bc1a84b4
b334553b37bf97a0c728d0687e3d234856c4f22c,Detecting planes and estimating their orientation from a single image,acf0b6745708457a53d5327eea345c0bcf466e97
94eab27b20b34593d5245ee93d5224d9b444f284,Layered Object Models for Image Segmentation,96dca25274d1d89d3b29bc0d08d089d1cdb181fe
d4e227d473ba7185eaf4e555fe5e1122da27bf30,Real-time estimation of 3D scene geometry from a single image,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
641f7b1eacd7280eea4d0966e67565820effc553,RECONSTRUCTING THREE-DIMENSIONAL SPECIFIC CURVE BUILDING MODELS FROM A SINGLE PERSPECTIVE VIEW IMAGE,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d77d5c4c55a223512460793669f3016a4efb37db
c6ad75d3d0c0ac7e712514bfa3e15e41f1c3dd13,Depth estimation from a single image and method of manufacturing 3D photo,3635881d5632816df7762f2c588138c0baa339ef$$@$$e36632f52c995e28896fa0663c39ae345d097da6
38cda7db037af1f7292726bad8af4ff106cd1b03,"Optical correlator based target detection, recognition, classification, and tracking.",5b1dcc50c7c23468f3a53226fb57fdd3e5993113
da358819ea1c984c976cdcdd472353e0dd1259dc,Which facial profile do humans expect after seeing a frontal view? a comparison with a linear face model,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113
2e0597fffc495e67ade645ab24017b76cae37387,Toward Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$a1466825412cdec8f853edf14d95de4c5edc0510$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
b51a15831dcba0649f1c39cbeaa7080939040075,A learning-based framework for depth ordering,4081e007d7eced95cc618164e976a80d44ff5f4e
817f38e6e9844d4513047916fe88561a758846e7,2D-to-3D image conversion by learning depth from examples,96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
113a31b4c58c613d5847b0d4b9890795d33e9189,Weakly supervised sparse coding with geometric consistency pooling,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
b1799fdccfa3c1327df09d3ef5a6b036eb45eea4,Efficient postprocessing of edge maps for image segmentation based on greedy correction cost minimization,5f985b914756155c92ebf474409be176bc1a84b4
3e5b4c9e01c8cd453021a86dc3982638f422b20e,Seeing Unseeability to See the Unseeable,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
2face695f4211142ad166e25f4dd827279b2e0ac,Single image depth estimation from image descriptors,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
396433b61da8f4b3ae23b538390846649cc73b7b,2D-to-3D conversion for single-view image based on camera projection model and dark channel model,cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
a8876d7f6b4dff6633e8dd773b3c4f54bc637692,Automatic 2D-to-3D image conversion using 3D examples from the internet,86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
f2acb02a1f94a973a1795fedc646bd6f14cbe24f,Supervised disparity estimation,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
7402411d86b724a3f7851795ecd801f8b9da48d4,Learning to place new objects in a scene,a1466825412cdec8f853edf14d95de4c5edc0510$$@$$3635881d5632816df7762f2c588138c0baa339ef
194135d5e321322d0e00732fc02efed2c2e26aee,Estimating Planar Structure in Single Images by Learning from Examples,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
a7d713f3b465feff60a5f897df9618f8c4b53103,Object-Graphs for Context-Aware Visual Category Discovery,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$c99f2391b956dc189855541e49e53c21ae5ec603
4cc8c1abb7a70b96244a8bc34b857c5929071eac,Restoration of Brick and Stone Relief from Single Rubbing Images,"3635881d5632816df7762f2c588138c0baa339ef$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$5ea3e6ef1012b9e7f39451364d68312595b544b8"
81b0792553955b79b1abb468938bef555a574c23,Reconstruction techniques for fixed 3-D lines and fixed 3-D points using the relative pose of one or two cameras,49531103099c8d17ea34eb09433688e84de4f35f$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1
678a54555a8606830f2cccd8bc9672c0ad28a903,2D to 3D conversion of sports content using panoramas,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
c1154caa764391f8523100d52bab543b0a6bdb66,Semantic Labeling of 3D Point Clouds for Indoor Scenes,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$c99f2391b956dc189855541e49e53c21ae5ec603
3eb9023ab2ddf705faea0b11ef38eabc770dd371,$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding,0b14178e7d79ac426d0a39700e1ac8b2c6f2e752$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$c99f2391b956dc189855541e49e53c21ae5ec603
09993767b3d06074c8e5ad26772e242e04a3b3b8,Adaptive reconstruction of human motion on wireless body sensor networks,3635881d5632816df7762f2c588138c0baa339ef
7778e709bcaef7de120cfed575c9ab6b35a9ba96,Learning to Produce 3D Media From a Captured 2D Video,5f985b914756155c92ebf474409be176bc1a84b4$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
cc905ef15b0ee7a37deb8490c7d55951731f65ef,Recovering Depth Map from Video with Moving Objects,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$5f985b914756155c92ebf474409be176bc1a84b4
11d096b9b89915f014332dd537b2124692e033db,Real-time indoor scene understanding using Bayesian filtering with motion cues,ae89592317675c9c7642a3976c3a064cef736f92$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$1f4789a2effea966c8fd10491fe859cfc7607137
c56edc80663dc5b66dd5a86a063074c090946f69,Image Coding Using Depth Blurring for Aesthetically Acceptable Distortion,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
71447d7842e8db16ab55858d29fc5c7fb12ec3a1,"A hypothesize-and-bound algorithm for simultaneous object classification, pose estimation and 3D reconstruction from a single 2D image",88da9026bbedf408aec54b158b456627818cacf9$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700
711bb1f38e159ca5594df233add205313f27fa84,High-quality tactile paintings,5f985b914756155c92ebf474409be176bc1a84b4
ff570cc01ae075e78875dee20daee6666e13332d,"Emergent Intelligent Behavior through Integrated Investigation of Embodied Natural Language, Reasoning, Learning, Computer Vision, and Robotic Manipulation",4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
5d01eb7d8ef2eb6920ede508e92960ed85d80909,"Hypothesize and Bound: A Computational Focus of Attention Mechanism for Simultaneous 3D Shape Reconstruction, Pose Estimation and Classification from a Single 2D Image",88da9026bbedf408aec54b158b456627818cacf9$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700
6eed1fd7c4f30c89f65441ca3f86c5d605a76126,Representations and Techniques for 3D Object Recognition and Scene Interpretation,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
d93d0c9816da9c6f4e4809b8ee338fcf9a59b560,3D video coding via motion compensation of superpixels,5f985b914756155c92ebf474409be176bc1a84b4
25469bac5afbbd586f7710d773c27c5c20ff57f1,3D visualization of single images using patch level depth,787827850b614135f6b432603afc90b58a8cc665$$@$$5144e666cdf2f33a5e1d96d763b29cb18472aef1$$@$$0200679f3219066be7c54a5bd7df17c33f3f2224$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$51890c0983d4e75f2c3d8d075cb24ef74cecd4a8$$@$$f6bca0356d66a0c21be3e91ccb5f740e5416d26e$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
fa94fe065ab19e4a19f70c335d47980227b4346a,Labeling 3D scenes for Personal Assistant Robots,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$6a4300efb6895695205dfc1b74e124f9fea6aff2$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
1acdafa1bef22898099737e7e83a8123e3b4e8c0,Semantic Structure from Motion: A Novel Framework for Joint Object Recognition and 3D Reconstruction,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe
659c15a3ea1d08bb3026bdf23c80a0d3e9eaf7cb,Learning to find occlusion regions,83fa51c8ca9144361d4ba26152e7cfa27d5c5649$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
7cad03f7c4516ac107f6fa548c977f646628a067,Automatic photo-to-terrain alignment for the annotation of mountain pictures,a31e9d09d90261fc68acffe097df592cfdcb7706
14f82a4e399947ac549008ff5f1da72f05aab0f9,A generative model for 3D urban scene understanding from movable platforms,d2f78c2b2b325d72f359d4c797c9aab6a8e60942
ddd0d71f7b647d3d01ae73a86c9e163097028d64,Semantic structure from motion,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe
24c95e937f6194fc05cfb9c641c403b009c97a72,Active learning for piecewise planar 3D reconstruction,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$d77d5c4c55a223512460793669f3016a4efb37db
52ee1692b1e83b3319cc1eae02557115f5ac6fcc,Global object placement relation for improving 3-D scene construction from single image,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
76f2a0f03fea36b227ee3e6e20b40669dc127b7f,Toward Automatic 3D Generic Object Modeling from One Single Image,82ebff86c9f862522d5a78ecac3717243daddd43$$@$$a31e9d09d90261fc68acffe097df592cfdcb7706
003d6ced7ec1923579e84b9facea6583a1227406,Autonomous MAV flight in indoor environments using single image perspective cues,3635881d5632816df7762f2c588138c0baa339ef$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
c4c2d6eff713ae135d79eb7c66925509906fea07,Design your room: adding virtual objects to a real indoor scenario,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
28cb118ed6f26440001cb85b52508eb4b3580991,Construction of 3D models from single view images: A survey based on various approaches,3635881d5632816df7762f2c588138c0baa339ef$$@$$5b1dcc50c7c23468f3a53226fb57fdd3e5993113$$@$$1f4789a2effea966c8fd10491fe859cfc7607137$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$88da9026bbedf408aec54b158b456627818cacf9$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$421e6c7247f41c419a46212477d7b29540cbf7b1$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$fdcde62b781ab7bd60aa76d4ec7328fbf9ab7c71$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb$$@$$e36632f52c995e28896fa0663c39ae345d097da6$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4$$@$$787827850b614135f6b432603afc90b58a8cc665
e206140235a9b639b67f88fe4fe23e1325d253a5,Off-road Robotics—An Overview,ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
3a1a10395026139a1e7d90a1022aaf2a29cc98d2,Rapid modeling of cones and cylinders from a single calibrated image using minimum 2D control points,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
55f4c7b6cbf970f42eaf12e2aa2827dc27e66d06,Estimating perception of scene layout properties from global image features.,668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$acf0b6745708457a53d5327eea345c0bcf466e97
078911586b4f29d1ccae9b6e89e44d35efc0cdd2,Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models,4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$3635881d5632816df7762f2c588138c0baa339ef$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$a1466825412cdec8f853edf14d95de4c5edc0510$$@$$c99f2391b956dc189855541e49e53c21ae5ec603$$@$$49531103099c8d17ea34eb09433688e84de4f35f$$@$$acf0b6745708457a53d5327eea345c0bcf466e97$$@$$2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$cddd92203c8deb022a29b512b11050da531c5f3b
4ef180e07cd412df719358baa79e315672a94ba7,A Smartphone-Based Obstacle Sensor for the Visually Impaired,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
c62aa6e126393d2073f42d7245620e391ce2e591,A Dynamic Programming Approach to Reconstructing Building Interiors,ae89592317675c9c7642a3976c3a064cef736f92
854b0a75c18244bfcf74e4a061d7682037618a3f,Occlusion Boundary Detection Using Pseudo-depth,0b14178e7d79ac426d0a39700e1ac8b2c6f2e752$$@$$668b1277fbece28c4841eeab1c97e4ebd0079700$$@$$83fa51c8ca9144361d4ba26152e7cfa27d5c5649
e37993b6612f433057f737ad37785743f3c4436b,Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics,1f4789a2effea966c8fd10491fe859cfc7607137
9f5cbb7295216d43247773d211295630012221f5,Thinking Inside the Box: Using Appearance Models and Context Based on Room Geometry,2e2a35ca0fe09d96130b0cf5dfad7af083560a71$$@$$4081e007d7eced95cc618164e976a80d44ff5f4e$$@$$96dca25274d1d89d3b29bc0d08d089d1cdb181fe$$@$$4a965ee6dcfc1ab12170af762e1d08e11b60ddb8
ecc25079023c2b3cc92450e91e724865c9757a31,Scene Carving: Scene Consistent Image Retargeting,4a965ee6dcfc1ab12170af762e1d08e11b60ddb8$$@$$d2f78c2b2b325d72f359d4c797c9aab6a8e60942
58afb412e41cfe2d77cdd89aa65e8f821bdd36d7,Semantic 3D Object Maps for Everyday Manipulation in Human Living Environments,ae89592317675c9c7642a3976c3a064cef736f92$$@$$a61de626cd5c949baa47f06ac1a864cfaca67ad5$$@$$86d21c2d53ce6a193ceb688bacbbb4ffec09a6cb
e4afb7a9ca9f708edf32d5d3343a2e5939328972,Image warps for artistic perspective manipulation,d77d5c4c55a223512460793669f3016a4efb37db
893ebdaeb66b2d0c5b5be100e2d19e54a3c0824e,Single image depth estimation from predicted semantic labels,1f4789a2effea966c8fd10491fe859cfc7607137$$@$$d77d5c4c55a223512460793669f3016a4efb37db$$@$$ae89592317675c9c7642a3976c3a064cef736f92$$@$$cddd92203c8deb022a29b512b11050da531c5f3b$$@$$5f985b914756155c92ebf474409be176bc1a84b4
dce6b537c8e643b446f3a8a2158cc6bbcfd1928c,Growing semantically meaningful models for visual SLAM,ae89592317675c9c7642a3976c3a064cef736f92